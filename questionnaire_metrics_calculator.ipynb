{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9ef7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data_handler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets\n",
    "import os\n",
    "from itertools import chain, product\n",
    "\n",
    "from scipy.stats import ttest_1samp, ttest_rel, t\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.path.curdir, \"data\", \"survey_results\", \"data_tu-helpfulness-of-xai_2022-07-13_13-03.xlsx\")\n",
    "DATA_PREPARED_PATH = f\"{os.path.splitext(DATA_PATH)[0]}_PREPARED{os.path.splitext(DATA_PATH)[1]}\"\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "df_merged = pd.read_excel(DATA_PREPARED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "META_DATA_PATH = os.path.join(os.path.curdir, \"data\", \"survey_results\", \"question_meta_data.xlsx\")\n",
    "df_quest_meta = pd.read_excel(META_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2286ea0",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculation & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de567e7",
   "metadata": {},
   "source": [
    "### Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_groupby(df_merged, group_by=[\"method\"], drop_na=False):\n",
    "    # accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    schema_cols = [df_merged[column].drop_duplicates() for column in group_by + [\"is_pred_correct\", \"response\"]]\n",
    "    schema_col_names = [ser.name for ser in schema_cols]\n",
    "    df_schema = pd.DataFrame(list(product(*schema_cols))).groupby(list(np.arange(len(schema_cols)))).count()\n",
    "    df_schema = df_schema.reset_index()\n",
    "    df_schema.columns=schema_col_names\n",
    "    \n",
    "    ser_denominators = df_merged.groupby(by=group_by, dropna=drop_na)[\"response\"].count().sort_index()\n",
    "    df_numerators = df_merged.groupby(by=group_by + [\"is_pred_correct\", \"response\"], dropna=drop_na)[\"response\"].count().to_frame(\"count\").reset_index()\n",
    "    df_numerators = df_schema.merge(right=df_numerators, on=schema_col_names, how=\"left\").fillna(0)\n",
    "    ser_numerators = df_numerators[df_numerators[\"is_pred_correct\"] == df_numerators[\"response\"]].groupby(group_by, dropna=drop_na)[\"count\"].sum().sort_index()\n",
    "    df_accuracies = (ser_numerators / ser_denominators).to_frame(\"accuracy\")\n",
    "    return df_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_per_groupby(df_merged, group_by=[\"method\"], drop_na=True):\n",
    "    # sensitivity = TP / (TP + FN)\n",
    "    schema_cols = [df_merged[column].drop_duplicates() for column in group_by + [\"is_pred_correct\", \"response\"]]\n",
    "    schema_col_names = [ser.name for ser in schema_cols]\n",
    "    df_schema = pd.DataFrame(list(product(*schema_cols))).groupby(list(np.arange(len(schema_cols)))).count()\n",
    "    df_schema = df_schema.reset_index()\n",
    "    df_schema.columns=schema_col_names\n",
    "    \n",
    "    df_merged_filt = df_merged[(df_merged[\"is_pred_correct\"] == True)]\n",
    "    ser_denominators = df_merged_filt.groupby(by=group_by, dropna=drop_na)[\"response\"].count().sort_index()\n",
    "    df_numerators = df_merged_filt.groupby(by=group_by + [\"is_pred_correct\", \"response\"], dropna=drop_na)[\"response\"].count().to_frame(\"count\").reset_index()\n",
    "    df_numerators = df_schema.merge(right=df_numerators, on=schema_col_names, how=\"left\").fillna(0)\n",
    "    ser_numerators = df_numerators[df_numerators[\"is_pred_correct\"] == df_numerators[\"response\"]].groupby(group_by, dropna=drop_na)[\"count\"].sum().sort_index()\n",
    "    df_sensitivity = (ser_numerators / ser_denominators).to_frame(\"sensitivity\")\n",
    "    return df_sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity_per_groupby(df_merged, group_by=[\"method\"], drop_na=True):\n",
    "    # specificity = TN / (TN + FP)\n",
    "    schema_cols = [df_merged[column].drop_duplicates() for column in group_by + [\"is_pred_correct\", \"response\"]]\n",
    "    schema_col_names = [ser.name for ser in schema_cols]\n",
    "    df_schema = pd.DataFrame(list(product(*schema_cols))).groupby(list(np.arange(len(schema_cols)))).count()\n",
    "    df_schema = df_schema.reset_index()\n",
    "    df_schema.columns=schema_col_names\n",
    "    \n",
    "    df_merged_filt = df_merged[(df_merged[\"is_pred_correct\"] == False)]\n",
    "    ser_denominators = df_merged_filt.groupby(by=group_by, dropna=drop_na)[\"response\"].count().sort_index()\n",
    "    df_numerators = df_merged_filt.groupby(by=group_by + [\"is_pred_correct\", \"response\"], dropna=drop_na)[\"response\"].count().to_frame(\"count\").reset_index()\n",
    "    df_numerators = df_schema.merge(right=df_numerators, on=schema_col_names, how=\"left\").fillna(0)\n",
    "    ser_numerators = df_numerators[df_numerators[\"is_pred_correct\"] == df_numerators[\"response\"]].groupby(group_by, dropna=drop_na)[\"count\"].sum().sort_index()\n",
    "    df_specificity = (ser_numerators / ser_denominators).to_frame(\"specificity\")\n",
    "    return df_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_convergence(df_metric):\n",
    "    metric_name = df_metric.columns[0]\n",
    "    return df_metric.groupby(level=0).expanding().mean().reset_index(level=[1, 2]).\\\n",
    "            pivot(index=\"case\", columns=\"method\", values=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c421b0f6",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_boxplot(df_metrics, by, column, xlabel=\"XAI-Method\", ylabel=\"Accuracy\", title=\"\"):\n",
    "    ax = df_metrics.boxplot(by=by, column=column, figsize=(14, 5), showmeans=True, meanline=True)\n",
    "    fig = plt.gcf()\n",
    "    fig.suptitle(None)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    #xai = df_metrics[]\n",
    "    #ax.plot([\"ConfidenceScores\", \"gradCAM\"], [0.5, 0.5], c=\"red\", linestyle=\"dashed\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0685da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensitivity_specificity(df_sens_mean, df_spec_mean, title_addition=\"\"):\n",
    "    df_sens_mean = df_sens_mean.sort_index()\n",
    "    df_spec_mean = df_spec_mean.sort_index()\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.scatter(x=df_sens_mean.index, y=df_sens_mean, c=\"darkorange\", label=\"Sensitivity: Guessed Correct when Model Correct\")\n",
    "    ax.scatter(x=df_spec_mean.index, y=df_spec_mean, c=\"olivedrab\", label=\"Specificity: Guessed Wrong when Model Wrong\", marker=\"^\")\n",
    "    ax.plot(df_sens_mean[\"mean\"].index, [0.5] * len(df_sens_mean), color=\"indianred\", linestyle='dashed', label=\"baseline\")\n",
    "    ax.set_title(f\"{title_addition} Performance Ratios for chosen XAI-Methods ({len(df)-1} participants considered)\", size=15)\n",
    "    ax.set_xlabel(\"XAI-Method\", size=13)\n",
    "    ax.set_ylabel(\"Ratio\", size=13)\n",
    "    for i, txt in enumerate(df_sens_mean[\"mean\"].round(2)):\n",
    "        ax.annotate(txt, (list(df_sens_mean.index)[i], list(df_sens_mean[\"mean\"])[i]))\n",
    "    for i, txt in enumerate(df_spec_mean[\"mean\"].round(2)):\n",
    "        ax.annotate(txt, (list(df_spec_mean.index)[i], list(df_spec_mean[\"mean\"])[i]))\n",
    "    ax.legend(loc=\"best\", edgecolor=\"black\")\n",
    "    ax.tick_params(labelright=True)\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    plt.savefig(\"ratios.svg\") # sens_vs_spec.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aac06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_convergence(df_metrics_conv, metric_name=\"Accuracy\"):\n",
    "    methods_sorted = df_metrics_conv.iloc[-1].sort_values(ascending=False).index.values\n",
    "    df_metrics_conv = df_metrics_conv[methods_sorted]\n",
    "    \n",
    "    methods_names = methods_sorted.copy()\n",
    "    methods_names.sort()\n",
    "    colors =[\"darkorange\", \"olivedrab\",\"lightseagreen\",\"darkslategrey\",\"royalblue\",\"mediumvioletred\"]\n",
    "    line = [\"dotted\",\"dashed\",\"dashdot\",\"dotted\",\"dashed\",\"dashdot\"]\n",
    "    colors_dict = dict(zip(methods_names, colors))\n",
    "    line_dict = dict(zip(methods_sorted, line))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.set_xlabel(\"Number Participants\", size=13)\n",
    "    ax.set_ylabel(\"Accuracy\", size=13)\n",
    "    #ax.set_title(f\"Convergence of {metric_name} as Number of Participants increase\", size=15)\n",
    "    df_metrics_conv.apply(lambda method_conv: ax.plot(list(range(len(method_conv))), method_conv, label=method_conv.name, color=colors_dict[method_conv.name],ls=line_dict[method_conv.name]))\n",
    "    ax.legend(loc=\"upper right\", edgecolor=\"black\")\n",
    "    ax.tick_params(labelright=True)\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    plt.savefig(\"convergence.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb30e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2_indexes_1_plot(df_double_index, xlabel, ylabel, title, drop_na=True, drop_duplicates=True, mean_idx_order=None):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "    plt.setp(ax, ylim=(0, 1.1))\n",
    "    if drop_duplicates:\n",
    "        ser_level_1_count = df_merged.drop_duplicates(\"case\").groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "    else:\n",
    "        ser_level_1_count = df_merged.groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "                                                                                                                            \n",
    "    ser_acc_mean = df_double_index.mean(level=0)[df_double_index.columns[0]]\n",
    "    # reorder bars in barplot as specified\n",
    "    if mean_idx_order:\n",
    "        ser_acc_mean = ser_acc_mean.reindex(mean_idx_order)\n",
    "                                                                                                                         \n",
    "    pps = ax[0].bar(ser_acc_mean.index, ser_acc_mean)\n",
    "    for p in pps:\n",
    "        height = p.get_height()\n",
    "        ax[0].text(x=p.get_x() + p.get_width() / 2, y=height+.05,\n",
    "          s=round(height, 2),\n",
    "          ha='center', size=12)\n",
    "    ax[0].set_xlabel(ser_acc_mean.index.name, size=15)\n",
    "    ax[0].set_ylabel(\"Accuracy\", size=15)\n",
    "    ax[0].set_title(f\"Mean Accuracy over all XAI-Methods per {ser_acc_mean.index.name}\", size=20)\n",
    "    \n",
    "    for idx_level_1 in df_double_index.index.levels[0]:\n",
    "        ax[1].plot(df_double_index.loc[idx_level_1].index, list(df_double_index.loc[idx_level_1][df_double_index.columns[0]]), label=f\"{idx_level_1} ({ser_level_1_count[idx_level_1]})\")\n",
    "        ax[1].scatter(df_double_index.loc[idx_level_1].index, list(df_double_index.loc[idx_level_1][df_double_index.columns[0]]))\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel(xlabel, size=15)\n",
    "    ax[1].set_ylabel(ylabel, size=15)\n",
    "    ax[1].set_title(title, size=20)\n",
    "    plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.3, wspace=0.4)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2405a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(df_double_index,filename ,drop_na=True, drop_duplicates=True, mean_idx_order=None):\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    if drop_duplicates:\n",
    "        ser_level_1_count = df_merged.drop_duplicates(\"case\").groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "    else:\n",
    "        ser_level_1_count = df_merged.groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "\n",
    "    ser_acc_mean = df_double_index.mean(level=0)[df_double_index.columns[0]]\n",
    "    # reorder bars in barplot as specified\n",
    "    if mean_idx_order:\n",
    "        ser_acc_mean = ser_acc_mean.reindex(mean_idx_order)\n",
    "\n",
    "    pps = ax.bar(ser_acc_mean.index, ser_acc_mean,color=\"olivedrab\")\n",
    "    for p in pps:\n",
    "        height = p.get_height()\n",
    "        ax.text(x=p.get_x() + p.get_width() / 2, y=height+.05,\n",
    "          s=round(height, 2),\n",
    "          ha='center', size=12)\n",
    "    ax.set_xlabel(ser_acc_mean.index.name, size=15)\n",
    "    ax.set_ylabel(\"Accuracy\", size=15)\n",
    "    #ax.set_title(f\"Mean Accuracy over all XAI-Methods per {ser_acc_mean.index.name}\", size=20)\n",
    "    ax.tick_params(labelright=True)\n",
    "    ax.set_ylim([0, 1])\n",
    "    plt.savefig(filename+\".svg\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4314b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot(df_double_index, xlabel, ylabel,filename, drop_na=True):\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "    colors =[\"darkorange\",\"olivedrab\"]\n",
    "    line = [\"dashed\",\"dashdot\"]\n",
    "    idx_level_1 = df_double_index.index.levels[0]\n",
    "\n",
    "    for i in range(idx_level_1.shape[0]):\n",
    "        ax.plot(df_double_index.loc[idx_level_1[i]].index, list(df_double_index.loc[idx_level_1[i]][df_double_index.columns[0]]),\n",
    "                label=f\"{idx_level_1[i]}\",color=colors[i],ls=line[i]) #({ser_level_1_count[idx_level_1]})\n",
    "        ax.scatter(df_double_index.loc[idx_level_1[i]].index, list(df_double_index.loc[idx_level_1[i]][df_double_index.columns[0]]),\n",
    "                   color=colors[i])\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_xlabel(xlabel, size=13)\n",
    "    ax.set_ylabel(ylabel, size=13)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.tick_params(labelright=True)\n",
    "    plt.savefig(filename+\".svg\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e652a0",
   "metadata": {},
   "source": [
    "### Testing & effect size functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isn't used currently\n",
    "def print_test_result(pval, alpha, mean_h_0):\n",
    "    print(f\"p-value: {pval}\")\n",
    "    if pval < alpha:\n",
    "        print(f\"Reject H0: accuracy_mean <= {mean_h_0} \\n\")\n",
    "    else:\n",
    "        print(\"Can't reject H0 \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9513aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_t_test(accuracies, mean_h_0, alpha, alternative):\n",
    "    tset, pval = ttest_1samp(a=accuracies, popmean=mean_h_0, alternative=alternative)\n",
    "    print(accuracies.name)\n",
    "    print(f\"p-value: {pval}\")\n",
    "    if pval < alpha:\n",
    "        print(f\"Reject H0: accuracy_mean <= {mean_h_0} \\n\")\n",
    "    else:\n",
    "        print(\"Can't reject H0 \\n\")\n",
    "    return tset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_t_test_with_flexible_alternative(metrics, mean_h_0, alpha):\n",
    "    h_a = None\n",
    "    sample_mean = metrics.mean()\n",
    "    if sample_mean < mean_h_0:\n",
    "        h_a = \"less\"\n",
    "    elif sample_mean > mean_h_0:\n",
    "        h_a = \"greater\"\n",
    "    else:\n",
    "        h_a = \"two-sided\"\n",
    "    tset, pval = ttest_1samp(a=metrics, popmean=mean_h_0, alternative=h_a)\n",
    "    \n",
    "    h_a_to_h_0_mapping = {\"less\": \">=\", \"greater\": \"<=\", \"two-sided\": \"equal\"}\n",
    "    print(f\"{metrics.name}:  sample_mean={sample_mean}\")\n",
    "    print(f\"H0: sample_mean {h_a_to_h_0_mapping[h_a]} {mean_h_0}\")\n",
    "    print(f\"p-value: {pval}\")\n",
    "    if pval < alpha:\n",
    "        print(f\"Reject H0! (alpha={alpha})\\n\")\n",
    "    else:\n",
    "        print(f\"Can't reject H0: (alpha={alpha})\\n\")\n",
    "    return tset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb5c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_paired_t_test_alternatives_and_p_values(df_metrics, df_metrics_mean):\n",
    "    paired_test_alternatives = []\n",
    "    paired_test_pvalues = []\n",
    "    df_metrics_mean = df_metrics_mean.sort_values(by=\"mean\", ascending=False)\n",
    "    xai_accuracy_sorted = df_metrics_mean.index.values\n",
    "    for method_i in xai_accuracy_sorted:\n",
    "        method_i_alternatives = []\n",
    "        method_i_pvalues = []\n",
    "        for method_j in xai_accuracy_sorted:\n",
    "            # h_a = \"less\" if df_metrics_mean.loc[method_i][\"mean\"] < df_metrics_mean.loc[method_j][\"mean\"] else \"greater\" if df_metrics_mean.loc[method_i][\"mean\"] > df_metrics_mean.loc[method_j][\"mean\"] else None\n",
    "            h_a = None\n",
    "            if df_metrics_mean.loc[method_i][\"mean\"] < df_metrics_mean.loc[method_j][\"mean\"]:\n",
    "                h_a = \"less\"\n",
    "            elif df_metrics_mean.loc[method_i][\"mean\"] > df_metrics_mean.loc[method_j][\"mean\"]:\n",
    "                h_a = \"greater\"\n",
    "            elif (df_metrics_mean.loc[method_i][\"mean\"] == df_metrics_mean.loc[method_j][\"mean\"]) & (method_i != method_j):\n",
    "                h_a = \"two-sided\"\n",
    "            method_i_alternatives.append(h_a)\n",
    "            if h_a is None:\n",
    "                method_i_pvalues.append(np.nan)\n",
    "            else:\n",
    "                a = df_metrics[method_i].values\n",
    "                b = df_metrics[method_j].values\n",
    "                tset, pval = ttest_rel(a, b, alternative=h_a)\n",
    "                method_i_pvalues.append(pval)\n",
    "        paired_test_alternatives.append(method_i_alternatives)\n",
    "        paired_test_pvalues.append(method_i_pvalues)\n",
    "        \n",
    "    df_paired_alternatives = pd.DataFrame(paired_test_alternatives, index=xai_accuracy_sorted, columns=xai_accuracy_sorted)\n",
    "    df_paired_alternatives.index.name = \"method_i\"\n",
    "    df_paired_alternatives.columns.name = \"method_j\"\n",
    "    \n",
    "    df_paired_pvalues = pd.DataFrame(paired_test_pvalues, index=xai_accuracy_sorted ,columns=xai_accuracy_sorted)\n",
    "    df_paired_pvalues.index.name = \"method_i\"\n",
    "    df_paired_pvalues.columns.name = \"method_j\"\n",
    "    \n",
    "    return df_paired_alternatives, df_paired_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erste Formel\n",
    "def cohens_d(mean_1, var_1, mean_2, var_2):\n",
    "    return (mean_1 - mean_2) / np.sqrt((var_1 + var_2) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohen’s d for one-sample t-test\n",
    "# https://www.youtube.com/watch?v=yGc1a324t14&ab_channel=Dr.ToddGrande (1-sample t-test)\n",
    "# https://www.youtube.com/watch?v=yVbYvn_cT5w&ab_channel=Dr.ToddGrande (2-sample t-test)\n",
    "# noch andere Quellen??? --> keine gefunden!\n",
    "def cohens_d_(t_statistic, N):\n",
    "    return t_statistic / np.sqrt(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff25b45",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c27e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance level\n",
    "ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503bc7a0",
   "metadata": {},
   "source": [
    "## 1. Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = accuracy_per_groupby(df_merged, group_by=[\"method\", \"case\"])\n",
    "df_acc_pivot = df_acc.reset_index().pivot(index=\"case\", columns=\"method\", values=\"accuracy\")\n",
    "df_acc_frequencies = df_acc_pivot.apply(lambda x: x.value_counts())\n",
    "df_acc_conv = get_metric_convergence(df_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627de95c",
   "metadata": {},
   "source": [
    "### Accuracy means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_mean = df_acc_pivot.mean().to_frame(\"mean\").sort_values(by=\"mean\", ascending=False)\n",
    "df_acc_mean.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall\n",
    "df_acc_mean.mean().to_frame(\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7feb37",
   "metadata": {},
   "source": [
    "### Accuracy boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_boxplot(df_acc.reset_index(), [\"method\"], \"accuracy\", title=\"Accuracy Variance among Participants per XAI-Method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f921c1e",
   "metadata": {},
   "source": [
    "### Accuracy convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772cd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_convergence(df_acc_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef82c2b",
   "metadata": {},
   "source": [
    "### Accuracy values  frequencies (all possible discrete according to question resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a57464",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_acc_frequencies[df_acc_mean.index].transpose().plot.bar(figsize=(13, 8))\n",
    "ax.set_ylabel(\"Number Participants who reached accuracy score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59784d8",
   "metadata": {},
   "source": [
    "### Significance & Effect Size: Accuracy comparisons to random baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0defbf7d",
   "metadata": {},
   "source": [
    "#### 1-sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c19801",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_h_0 = 0.5\n",
    "alternative_acc = \"greater\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf64255",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_acc_1_sample_t_values = df_acc_pivot.apply(lambda accuracies_method: perform_t_test(accuracies_method, mean_h_0, ALPHA, alternative_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91963358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with flexibile alternative\n",
    "df_acc_pivot.apply(lambda accuracies_method: perform_t_test_with_flexible_alternative(accuracies_method, mean_h_0, ALPHA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947fed9",
   "metadata": {},
   "source": [
    "#### Effect size (Cohens d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eab4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_random_guess = 0.5\n",
    "variance_random_guess = 0.0625 # deriviation via binomial distribution of correct answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a359cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_var = df_acc_pivot.var().to_frame(\"var\")\n",
    "df_cohens_d = pd.concat([df_acc_mean.T, df_acc_var.T])\n",
    "df_random_mean_var = pd.DataFrame({\"mean_random\" : [mean_random_guess]*6, \"var_random\": [variance_random_guess]*6}, index=df_cohens_d.columns).T\n",
    "df_cohens_d = pd.concat([df_cohens_d, df_random_mean_var])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b3f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In welcher Reihenfolge müssen werte cohends_d Formel übergegebn werden, damit es wie interpretiert werden kann?\n",
    "df_cohens_d.apply(lambda x: cohens_d(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4427a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nochmal mit Formel für \n",
    "N_acc = df_acc_pivot.shape[0]\n",
    "df_acc_1_sample_effect = ser_acc_1_sample_t_values.map(lambda t_val: cohens_d_(t_val, N_acc)).to_frame(\"cohens_d\").sort_values(by=\"cohens_d\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef69576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_1_sample_effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef236204",
   "metadata": {},
   "source": [
    "### Significance & Effect Size: Accuracies pairwise between each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c27b6",
   "metadata": {},
   "source": [
    "#### Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66efa54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_paired_test_alternatives, df_acc_apaired_test_pvalues = get_pairwise_paired_t_test_alternatives_and_p_values(df_acc_pivot, df_acc_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_paired_test_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_apaired_test_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_apaired_test_pvalues < ALPHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ddd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7a51d",
   "metadata": {},
   "source": [
    "#### Effect size in compare (Cohens d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c49b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e8b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18de71fd",
   "metadata": {},
   "source": [
    "## 2. Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd85468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens = sensitivity_per_groupby(df_merged, group_by=[\"method\", \"case\"])\n",
    "df_sens_pivot = df_sens.reset_index().pivot(index=\"case\", columns=\"method\", values=\"sensitivity\")\n",
    "df_sens_frequencies = df_sens_pivot.apply(lambda x: x.value_counts())\n",
    "df_sens_conv = get_metric_convergence(df_sens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d67a6b",
   "metadata": {},
   "source": [
    "### Sensitivity means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68312cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_mean = df_sens_pivot.mean().to_frame(\"mean\").sort_values(by=\"mean\", ascending=False)\n",
    "df_sens_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b0c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall\n",
    "df_sens_mean.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f19fb4",
   "metadata": {},
   "source": [
    "### Sensitivity boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b219dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_boxplot(df_sens.reset_index(), [\"method\"], \"sensitivity\", title=\"Sensitivity Variance among Participants per XAI-Method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340384c",
   "metadata": {},
   "source": [
    "### Sensitvity convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed0bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_convergence(df_sens_conv, metric_name=\"Sensitivity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904f60e",
   "metadata": {},
   "source": [
    "### Sensitivity values  frequencies (all possible discrete according to question resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061e45c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = df_sens_frequencies[df_sens_mean.index].transpose().plot.bar(figsize=(13, 8))\n",
    "ax.set_ylabel(\"Number Participants who reached accuracy score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2991bd",
   "metadata": {},
   "source": [
    "### Significance & Effect Size: Sensitivity comparisons to random baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9975db4",
   "metadata": {},
   "source": [
    "#### 1-sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d4c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_h_0 = 0.5\n",
    "alternative_sens = \"greater\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231de1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_sens_1_sample_t_values = df_sens_pivot.apply(lambda metric_method: perform_t_test(metric_method, mean_h_0, ALPHA, alternative_sens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0389a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with flexibile alternative\n",
    "df_sens_pivot.apply(lambda metric_method: perform_t_test_with_flexible_alternative(metric_method, mean_h_0, ALPHA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f946ac",
   "metadata": {},
   "source": [
    "#### Effect size (Cohens d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7fef7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff5037c",
   "metadata": {},
   "source": [
    "### Significance & Effect Size: Sensitivity pairwise between in each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8cc3ed",
   "metadata": {},
   "source": [
    "#### Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd12f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_paired_test_alternatives, df_sens_apaired_test_pvalues = get_pairwise_paired_t_test_alternatives_and_p_values(df_sens_pivot, df_sens_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1cdb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_paired_test_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_apaired_test_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474dd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_apaired_test_pvalues < ALPHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c4318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Results for Sensitivity (rowise and only the upper diagonal because symmetric)\n",
    "\n",
    "# gradCAM's sensitivity isnt't significantly greater than CS's and LRP's but bigger than of LIME, IG and SHAP\n",
    "# CS's sensitivity isnt't significantly greater than LRP's but bigger than of LIME, IG and SHAP\n",
    "# LRP's sensitivity is significantly greater than LIME's, IG's and SHAP's.\n",
    "# LIME's sensitivity isn't significantly greater than IG's but bigger than SHAP's\n",
    "# IG's sensitivity is significantly greater than SHAPS's.\n",
    "# (SHAPS sensitivity is significantly smaller than all others) --> this is an implication of the above mentioned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a9f7d",
   "metadata": {},
   "source": [
    "#### Effect size in compare (Cohens d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d5eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55d26968",
   "metadata": {},
   "source": [
    "## 3. Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6650b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec = specificity_per_groupby(df_merged, group_by=[\"method\", \"case\"])\n",
    "df_spec_pivot = df_spec.reset_index().pivot(index=\"case\", columns=\"method\", values=\"specificity\")\n",
    "df_spec_frequencies = df_spec_pivot.apply(lambda x: x.value_counts())\n",
    "df_spec_conv = get_metric_convergence(df_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113155df",
   "metadata": {},
   "source": [
    "### Specificity means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52467ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_mean = df_spec_pivot.mean().to_frame(\"mean\").sort_values(by=\"mean\", ascending=False)\n",
    "df_spec_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall\n",
    "df_spec_mean.mean().to_frame(\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37acd0",
   "metadata": {},
   "source": [
    "### Specificity boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe6d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_boxplot(df_spec.reset_index(), [\"method\"], \"specificity\", title=\"Specificity Variance among Participants per XAI-Method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175a294",
   "metadata": {},
   "source": [
    "### Specificity convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021619f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_convergence(df_spec_conv, metric_name=\"Specificity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b54f5",
   "metadata": {},
   "source": [
    "### Specificity values frequencies (all possible discrete according to question resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_sens_frequencies[df_sens_mean.index].transpose().plot.bar(figsize=(13, 8))\n",
    "ax.set_ylabel(\"Number Participants who reached accuracy score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b890759",
   "metadata": {},
   "source": [
    "### Significance & Effect Size: Specificity comparisons to random baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430622f",
   "metadata": {},
   "source": [
    "#### 1-sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_h_0 = 0.5\n",
    "alternative_spec = \"greater\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_spec_1_sample_t_values = df_spec_pivot.apply(lambda metric_method: perform_t_test(metric_method, mean_h_0, ALPHA, alternative_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with flexibile alternative\n",
    "df_spec_pivot.apply(lambda metric_method: perform_t_test_with_flexible_alternative(metric_method, mean_h_0, ALPHA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c01249e",
   "metadata": {},
   "source": [
    "#### Effect size (Cohens d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e7c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c4022af",
   "metadata": {},
   "source": [
    "### Significance & Effect Size: Specificity pairwise between in each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ceae0d",
   "metadata": {},
   "source": [
    "#### Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f27a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_paired_test_alternatives, df_spec_apaired_test_pvalues = get_pairwise_paired_t_test_alternatives_and_p_values(df_spec_pivot, df_spec_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03338bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_paired_test_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f348b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_apaired_test_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828464e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_apaired_test_pvalues < ALPHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Results for Specificity (rowise and only the upper diagonal because symmetric)\n",
    "\n",
    "# SHAPS's specificity is significantly greater than of all other methods\n",
    "# CS's specificity is significantly greater than of IG, LIME, gradCAM, LRP\n",
    "# IG's specificity isn't significantly greater LIME's but greater than gradCAM's and LRP's.\n",
    "# LIME's specifcity is significantly greater than gradCAM's and LRP's\n",
    "# gradCAM's specifcity isn't significantly greater than LRP's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2739d1",
   "metadata": {},
   "source": [
    "#### Effect size in compare (Cohens d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4da7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "532c200e",
   "metadata": {},
   "source": [
    "## 4. Sensitivity vs. Specificity per method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2af0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivity_specificity(df_sens_mean, df_spec_mean, title_addition=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48698abf",
   "metadata": {},
   "source": [
    "#### Sensitvity/ Specificity only on fixed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_img_idxs = df_quest_meta[\"img_idx\"].value_counts()[df_quest_meta[\"img_idx\"].value_counts() == 12].index\n",
    "df_quest_meta_fixed = df_quest_meta[df_quest_meta[\"img_idx\"].isin(fixed_img_idxs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3a082",
   "metadata": {},
   "source": [
    "## 5. Analysis: Participants characteristics on accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8356d",
   "metadata": {},
   "source": [
    "### Accuracy for different education levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abdc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_edu_method = accuracy_per_groupby(df_merged, group_by=[\"Education\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_edu_method, \"XAI Method\", \"Accuracy\", \"Accuracy Scores for different XAI Methods for different Education Levels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_edu_method,\"education\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab16720",
   "metadata": {},
   "source": [
    "### Accuracy for different ML-Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf075171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_mlex_method = accuracy_per_groupby(df_merged, group_by=[\"ML Experience\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ff9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_mlex_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different ML Experience Length\", mean_idx_order=[\"Not at all\", \"Under 1 year\", \"Between 1 and 3 years\", \"Between 3 and 5 years\", \"More than 5 years\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_mlex_method,\"ml_exp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62fd56b",
   "metadata": {},
   "source": [
    "### Accuracy for different perceived ML-Experience Usefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d674cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_xaiusef_method = accuracy_per_groupby(df_merged, group_by=[\"ML Experience Usefulness\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867296c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_xaiusef_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different perceived ML-Experience Usefulness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_xaiusef_method,\"ml_exp_self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531da57",
   "metadata": {},
   "source": [
    "### Accuracy for visual impairment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b864312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_visimp_method = accuracy_per_groupby(df_merged, group_by=[\"Visual Impairment Affect\", \"method\"], drop_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54d649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_visimp_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Visual Impairment Affect\", drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c2d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_visimp_method,\"visual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173388bd",
   "metadata": {},
   "source": [
    "### Accuracy for colorblindness yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de88eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_colorb_method = accuracy_per_groupby(df_merged, group_by=[\"Color Blindness\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d0064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_colorb_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Color Blindness\", drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266d0b8",
   "metadata": {},
   "source": [
    "## 6. Accuracy for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_model_method = accuracy_per_groupby(df_merged, group_by=[\"model\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07abbe67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_model_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Models\", drop_duplicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff99c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot(df_accuracy_model_method, \"XAI Method\", \"Accuracy\",\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe35a31",
   "metadata": {},
   "source": [
    "## 7. Metrics per questionnaire form (detect outlier questionnaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed8cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_qustnr_method = accuracy_per_groupby(df_merged, group_by=[\"QUESTNNR\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc581e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_qustnr_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Questionnaire Forms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ec2dd",
   "metadata": {},
   "source": [
    "#### Accuracy confidence intervalls per method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aed33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = accuracy_per_groupby(df_merged, group_by=[\"method\", \"case\"]).mean(level=0),\n",
    "N = accuracy_per_groupby(df_merged, group_by=[\"method\", \"case\"]).count(level=0)\n",
    "std = accuracy_per_groupby(df_merged, group_by=[\"method\", \"case\"]).std(level=0)\n",
    "degf = N - 1\n",
    "\n",
    "low_bounds, upp_bounds = stats.t.interval(0.95, degf,loc=loc, scale=std/np.sqrt(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc173c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ccb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "upp_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d76fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e6e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d032b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}