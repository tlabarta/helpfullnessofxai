{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9ef7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import chain, product\n",
    "\n",
    "from development import data_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2286ea0",
   "metadata": {},
   "source": [
    "# Metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a72f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/survey_results/data_tu-helpfulness-of-xai_2022-07-13_13-03.xlsx\"\n",
    "DATA_PREPARED_PATH = f\"{DATA_PATH.rsplit('.',1)[0]}_PREPARED.{DATA_PATH.rsplit('.',1)[1]}\"\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "df_merged = pd.read_excel(DATA_PREPARED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9906aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quest_meta = pd.read_excel(\"../data/survey_results/question_meta_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de567e7",
   "metadata": {},
   "source": [
    "## Metrics on all images (fixed + random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e01e8",
   "metadata": {},
   "source": [
    "### Overall ability to guess model is correct if actually correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51274ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit calculation of ratios as verification for grouped calulations further below\n",
    "num_guessed_correct_if_correct = df_merged[(df_merged[\"is_pred_correct\"] == True) & (df_merged[\"response\"] == True)].shape[0]\n",
    "num_correct_overall = df_merged[df_merged[\"is_pred_correct\"] == True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcff734",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_guessed_correct_if_correct / num_correct_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc6ea8",
   "metadata": {},
   "source": [
    "### Overall ability to guess model is wrong if actually wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b41eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_guessed_wrong_if_wrong = df_merged[(df_merged[\"is_pred_correct\"] == False) & (df_merged[\"response\"] == False)].shape[0]\n",
    "num_wrong_overall = df_merged[df_merged[\"is_pred_correct\"] == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_guessed_wrong_if_wrong / num_wrong_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d109a",
   "metadata": {},
   "source": [
    "### Ability for each XAI-method to guess model is correct/wrong if actually correct/wrong & general accuray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_groupby(df_merged, group_by=[\"method\"], drop_na=False):\n",
    "    # ACCURACY = (TP + TN) / (TP + TN + FP + FN)\n",
    "    schema_cols = [df_merged[column].drop_duplicates() for column in group_by + [\"is_pred_correct\", \"response\"]]\n",
    "    schema_col_names = [ser.name for ser in schema_cols]\n",
    "    df_schema = pd.DataFrame(list(product(*schema_cols))).groupby(list(np.arange(len(schema_cols)))).count()\n",
    "    df_schema = df_schema.reset_index()\n",
    "    df_schema.columns=schema_col_names\n",
    "    \n",
    "    ser_denominators = df_merged.groupby(by=group_by, dropna=drop_na)[\"response\"].count().sort_index()\n",
    "    df_numerators = df_merged.groupby(by=group_by + [\"is_pred_correct\", \"response\"], dropna=drop_na)[\"response\"].count().to_frame(\"count\").reset_index()\n",
    "    df_numerators = df_schema.merge(right=df_numerators, on=schema_col_names, how=\"left\").fillna(0)\n",
    "    ser_numerators = df_numerators[df_numerators[\"is_pred_correct\"] == df_numerators[\"response\"]].groupby(group_by, dropna=drop_na)[\"count\"].sum().sort_index()\n",
    "    df_accuracies = (ser_numerators / ser_denominators).to_frame(\"accuracy\")\n",
    "    return df_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1291eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = accuracy_per_groupby(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy overall\n",
    "df_accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f03b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_ratios(df_merged):\n",
    "    # CORRECT = TP / TP + FN; WRONG = TN / TN + FP\n",
    "    df_ratios_per_method = df_merged.groupby(by=[\"method\", \"is_pred_correct\"])[\"response\"].value_counts(normalize=True).to_frame(\"ratio\").reset_index()\n",
    "    df_ratios_per_method = df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == df_ratios_per_method[\"response\"]].reset_index(drop=True)\n",
    "    # append overall averages\n",
    "    df_ratios_per_method.loc[len(df_ratios_per_method)] = [\"Overall\", False, False, df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == False][\"ratio\"].mean()]\n",
    "    df_ratios_per_method.loc[len(df_ratios_per_method)] = [\"Overall\", True, True, df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == True][\"ratio\"].mean()]\n",
    "    return df_ratios_per_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_per_method = create_individual_ratios(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_per_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratios(df_ratios_per_method, title_addition=\"\"):        \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.scatter(x=df_ratios_per_method[\"method\"].drop_duplicates(),\n",
    "               y=df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == True][\"ratio\"],\n",
    "               c=\"darkorange\", label=\"Sensitivity: Guessed Correct when Model predicted Correct\")\n",
    "    ax.scatter(x=df_ratios_per_method[\"method\"].drop_duplicates(),\n",
    "               y=df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == False][\"ratio\"],\n",
    "               c=\"olivedrab\", label=\"Specitivity: Guessed Wrong when Model predicted Wrong\",marker=\"^\")\n",
    "    ax.plot(df_ratios_per_method[\"method\"], [0.5] * len(df_ratios_per_method), color=\"indianred\", linestyle='dashed', label=\"baseline\")\n",
    "    #ax.set_title(f\"{title_addition} Performance Ratios for chosen XAI-Methods ({len(df)} participants considered)\", size=15)\n",
    "    ax.set_xlabel(\"XAI-Method\", size=13)\n",
    "    ax.set_ylabel(\"Ratio\", size=13)\n",
    "    for i, txt in enumerate(df_ratios_per_method[\"ratio\"].round(2)):\n",
    "        ax.annotate(txt, (list(df_ratios_per_method[\"method\"])[i], list(df_ratios_per_method[\"ratio\"])[i]))\n",
    "    ax.legend(loc=\"best\", edgecolor=\"black\")\n",
    "    ax.tick_params(labelright=True)\n",
    "    plt.savefig(\"ratios.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ratios(df_ratios_per_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48698abf",
   "metadata": {},
   "source": [
    "## Metrics only on fixed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_img_idxs = df_quest_meta[\"img_idx\"].value_counts()[df_quest_meta[\"img_idx\"].value_counts() == 12].index\n",
    "df_quest_meta_fixed = df_quest_meta[df_quest_meta[\"img_idx\"].isin(fixed_img_idxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_fixed = df_merged[df_merged[\"img_idx\"].isin(fixed_img_idxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_per_method_fixed = create_individual_ratios(df_merged_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ratios(df_ratios_per_method_fixed, \"Fixed Imgs:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ec504",
   "metadata": {},
   "source": [
    "## Boxplots over individual participants metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_boxplot(df_metrics, by, column, xlabel=\"XAI-Method\", ylabel=\"Accuracy\", title=\"\"):\n",
    "    ax = df_metrics.boxplot(by=by, column=column, figsize=(14, 5))\n",
    "    fig = plt.gcf()\n",
    "    fig.suptitle(None)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    #xai = df_metrics[]\n",
    "    #ax.plot([\"ConfidenceScores\", \"gradCAM\"], [0.5, 0.5], c=\"red\", linestyle=\"dashed\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_boxplot(accuracy_per_groupby(df_merged, [\"method\", \"case\"]).reset_index(), [\"method\"], \"accuracy\", title=\"Accuracy Variance among Participants per XAI-Method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1dd3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_convergence_false = df_ratios_convergence[df_ratios_convergence.index.get_level_values(1) == False].reset_index()\n",
    "plot_metric_boxplot(df_ratios_convergence_false, [\"method\"], \"ratio\", ylabel=\"Specitivity\", title=\"Specitivity Variance among Participants per XAI-Method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c81998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_convergence_true = df_ratios_convergence[df_ratios_convergence.index.get_level_values(1) == True]\n",
    "plot_metric_boxplot(df_ratios_convergence_true, [\"method\"], \"ratio\", ylabel=\"Sensitivity\", title=\"Sensitivity Variance among Participants per XAI-Method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be527c41",
   "metadata": {},
   "source": [
    "## Convergence of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_ratios_per_participant(df_merged):\n",
    "    # df_schema needed to get all TP,TN,FP,FN i.e. where value_counts() would evaluate nothing because not existent (0)\n",
    "    df_schema = pd.DataFrame(list(product(df_merged[\"case\"].drop_duplicates(), df_merged[\"method\"].drop_duplicates(), df_merged[\"is_pred_correct\"].drop_duplicates(), df_merged[\"response\"].drop_duplicates()))).groupby([0, 1, 2, 3]).count()\n",
    "    df_schema = df_schema.reset_index()\n",
    "    df_schema.columns=['case', 'method', 'is_pred_correct', 'response']\n",
    "    df_ratios_per_method_and_part = df_merged.groupby(by=[\"case\", \"method\", \"is_pred_correct\"])[\"response\"].value_counts(normalize=True).to_frame(\"ratio\").reset_index()\n",
    "    df_ratios_per_method_and_part = df_schema.merge(right=df_ratios_per_method_and_part, on=[\"case\", \"method\", \"is_pred_correct\", \"response\"], how=\"left\")\n",
    "    df_ratios_per_method_and_part = df_ratios_per_method_and_part.fillna(0)\n",
    "    # only filter for TP and TP (just for now, might get modified)\n",
    "    df_ratios_per_method_and_part = df_ratios_per_method_and_part[df_ratios_per_method_and_part[\"is_pred_correct\"] == df_ratios_per_method_and_part[\"response\"]].reset_index(drop=True)\n",
    "    return df_ratios_per_method_and_part.groupby(by=[\"method\", \"is_pred_correct\"]).expanding().mean()#.reset_index(level=2, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6bb52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_convergence = create_individual_ratios_per_participant(df_merged)\n",
    "df_ratios_convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratio_convergence(df_ratios_convergence):\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.set_xlabel(\"Number Participants\", size=13)\n",
    "    ax.set_ylabel(\"Ratio\", size=13)\n",
    "    ax.set_title(\"Convergence of Ratios as Ratios are calculated over increasing Numbers of Participants\", size=15)\n",
    "    for method in df_ratios_convergence.index.get_level_values(0).drop_duplicates():\n",
    "        for outcome in df_ratios_convergence.index.get_level_values(1).drop_duplicates():\n",
    "            ax.plot(list(range(len(df_ratios_convergence.loc[method, outcome]))), df_ratios_convergence.loc[method, outcome][\"ratio\"], label=f\"{method}, {outcome}\")\n",
    "            print(df_ratios_convergence.loc[method, outcome][\"ratio\"].iloc[-1])\n",
    "    ax.legend(loc=\"lower center\", edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa217aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_convergence(df_accuracy_conv):\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.set_xlabel(\"Number Participants\", size=13)\n",
    "    ax.set_ylabel(\"Accuracy\", size=13)\n",
    "    #ax.set_title(\"Convergence of Accuracies as Number of Participants increase\", size=15)\n",
    "    colors =[\"darkorange\", \"olivedrab\",\"lightseagreen\",\"darkslategrey\",\"royalblue\",\"mediumvioletred\"]\n",
    "    line = [\"dotted\",\"dashed\",\"dashdot\",\"dotted\",\"dashed\",\"dashdot\"]\n",
    "    methods = df_accuracy_conv.index.get_level_values(0).drop_duplicates()\n",
    "    for i in range(len(methods)):\n",
    "        ax.plot(list(range(len(df_accuracy_conv.loc[methods[i]]))),\n",
    "                df_accuracy_conv.loc[methods[i]][\"accuracy\"], label=f\"{methods[i]}\",\n",
    "                color=colors[i],ls=line[i])\n",
    "            # print(df_ratios_convergence.loc[method, outcome][\"ratio\"].iloc[-1])\n",
    "    ax.legend(loc=\"upper right\", edgecolor=\"black\")\n",
    "    ax.tick_params(labelright=True)\n",
    "    plt.savefig(\"convergence.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479809ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_conv = accuracy_per_groupby(df_merged, [\"method\", \"case\"]).groupby(level=0).expanding().mean().reset_index(level=[1, 2], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_convergence(df_accuracy_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60537b9",
   "metadata": {},
   "source": [
    "## Metrics per questionnaire form (detect outlier questionnaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d25ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_qustnr_method = accuracy_per_groupby(df_merged, group_by=[\"QUESTNNR\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ab9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_qustnr_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Questionnaire Forms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1da3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_ratios_per_questionnaire(df_merged):\n",
    "    df_ratios_per_method = df_merged.groupby(by=[\"QUESTNNR\", \"method\", \"is_pred_correct\"])[\"response\"].value_counts(normalize=True).to_frame(\"ratio\").reset_index()\n",
    "    df_ratios_per_method = df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == df_ratios_per_method[\"response\"]].reset_index(drop=True)\n",
    "    # append overall averages\n",
    "    #df_ratios_per_method.loc[len(df_ratios_per_method)] = [\"Overall\", False, False, df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == False][\"ratio\"].mean()]\n",
    "    #df_ratios_per_method.loc[len(df_ratios_per_method)] = [\"Overall\", True, True, df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == True][\"ratio\"].mean()]\n",
    "    return df_ratios_per_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966274ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_qustn = create_individual_ratios_per_questionnaire(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5415b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplot_over_qnrs_per_method(df_ratios_qustn):\n",
    "    fig, ax = plt.subplots(6, 1, figsize=(20, 6*5))\n",
    "    for meth_idx, meth in enumerate(df_ratios_qustn.index.levels[0]):\n",
    "        for out_idx, out in enumerate(df_ratios_qustn.index.levels[1]):\n",
    "            ax[meth_idx].scatter(df_ratios_qustn.loc[meth, out][\"QUESTNNR\"], df_ratios_qustn.loc[meth, out][\"ratio\"], label=out)\n",
    "            ax[meth_idx].set_title(meth)\n",
    "            ax[meth_idx].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b4472",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_ratios_qustn.boxplot(by=[\"method\", \"is_pred_correct\"], column=\"ratio\", figsize=(20, 5))\n",
    "ax.set_ylabel(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each boxplot was genereated on the basis of 12 ratio values origin from the 12 questionnaires.\n",
    "# interpretation: per method an output the ratios vary quite a lot over the 12 questionnaires.\n",
    "# for a more drilled down view on each single ratio per method and questionnaire form see comprehensive view below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratios_per_questionnaire(df_ratios_qustn):\n",
    "    df_ratios_qustn = df_ratios_qustn.set_index([\"method\", \"is_pred_correct\"])\n",
    "    fig, ax = plt.subplots(6, 1, figsize=(20, 6*5))\n",
    "    for meth_idx, meth in enumerate(df_ratios_qustn.index.levels[0]):\n",
    "        for out_idx, out in enumerate(df_ratios_qustn.index.levels[1]):\n",
    "            ax[meth_idx].scatter(df_ratios_qustn.loc[meth, out][\"QUESTNNR\"], df_ratios_qustn.loc[meth, out][\"ratio\"], label=out)\n",
    "            ax[meth_idx].set_title(meth)\n",
    "            ax[meth_idx].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c01091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_ratios_per_questionnaire(df_ratios_qustn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e97990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot(df_double_index, xlabel, ylabel,filename, drop_na=True):\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "    colors =[\"darkorange\",\"olivedrab\"]\n",
    "    line = [\"dashed\",\"dashdot\"]\n",
    "    idx_level_1 = df_double_index.index.levels[0]\n",
    "\n",
    "    for i in range(idx_level_1.shape[0]):\n",
    "        ax.plot(df_double_index.loc[idx_level_1[i]].index, list(df_double_index.loc[idx_level_1[i]][df_double_index.columns[0]]),\n",
    "                label=f\"{idx_level_1[i]}\",color=colors[i],ls=line[i]) #({ser_level_1_count[idx_level_1]})\n",
    "        ax.scatter(df_double_index.loc[idx_level_1[i]].index, list(df_double_index.loc[idx_level_1[i]][df_double_index.columns[0]]),\n",
    "                   color=colors[i])\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_xlabel(xlabel, size=13)\n",
    "    ax.set_ylabel(ylabel, size=13)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.tick_params(labelright=True)\n",
    "    plt.savefig(filename+\".svg\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def bar_plot(df_double_index,filename ,drop_na=True, drop_duplicates=True, mean_idx_order=None):\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    if drop_duplicates:\n",
    "        ser_level_1_count = df_merged.drop_duplicates(\"case\").groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "    else:\n",
    "        ser_level_1_count = df_merged.groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "\n",
    "    ser_acc_mean = df_double_index.mean(level=0)[df_double_index.columns[0]]\n",
    "    # reorder bars in barplot as specified\n",
    "    if mean_idx_order:\n",
    "        ser_acc_mean = ser_acc_mean.reindex(mean_idx_order)\n",
    "\n",
    "    pps = ax.bar(ser_acc_mean.index, ser_acc_mean,color=\"olivedrab\")\n",
    "    for p in pps:\n",
    "        height = p.get_height()\n",
    "        ax.text(x=p.get_x() + p.get_width() / 2, y=height+.05,\n",
    "          s=round(height, 2),\n",
    "          ha='center', size=12)\n",
    "    ax.set_xlabel(ser_acc_mean.index.name, size=15)\n",
    "    ax.set_ylabel(\"Accuracy\", size=15)\n",
    "    #ax.set_title(f\"Mean Accuracy over all XAI-Methods per {ser_acc_mean.index.name}\", size=20)\n",
    "    ax.tick_params(labelright=True)\n",
    "    ax.set_ylim([0, 1])\n",
    "    plt.savefig(filename+\".svg\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2_indexes_1_plot(df_double_index, xlabel, ylabel, title, drop_na=True, drop_duplicates=True, mean_idx_order=None):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "    plt.setp(ax, ylim=(0, 1.1))\n",
    "    if drop_duplicates:\n",
    "        ser_level_1_count = df_merged.drop_duplicates(\"case\").groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "    else:\n",
    "        ser_level_1_count = df_merged.groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "                                                                                                                            \n",
    "    ser_acc_mean = df_double_index.mean(level=0)[df_double_index.columns[0]]\n",
    "    # reorder bars in barplot as specified\n",
    "    if mean_idx_order:\n",
    "        ser_acc_mean = ser_acc_mean.reindex(mean_idx_order)\n",
    "                                                                                                                         \n",
    "    pps = ax[0].bar(ser_acc_mean.index, ser_acc_mean)\n",
    "    for p in pps:\n",
    "        height = p.get_height()\n",
    "        ax[0].text(x=p.get_x() + p.get_width() / 2, y=height+.05,\n",
    "          s=round(height, 2),\n",
    "          ha='center', size=12)\n",
    "    ax[0].set_xlabel(ser_acc_mean.index.name, size=15)\n",
    "    ax[0].set_ylabel(\"Accuracy\", size=15)\n",
    "    ax[0].set_title(f\"Mean Accuracy over all XAI-Methods per {ser_acc_mean.index.name}\", size=20)\n",
    "    \n",
    "    for idx_level_1 in df_double_index.index.levels[0]:\n",
    "        ax[1].plot(df_double_index.loc[idx_level_1].index, list(df_double_index.loc[idx_level_1][df_double_index.columns[0]]), label=f\"{idx_level_1} ({ser_level_1_count[idx_level_1]})\")\n",
    "        ax[1].scatter(df_double_index.loc[idx_level_1].index, list(df_double_index.loc[idx_level_1][df_double_index.columns[0]]))\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel(xlabel, size=15)\n",
    "    ax[1].set_ylabel(ylabel, size=15)\n",
    "    ax[1].set_title(title, size=20)\n",
    "    plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.3, wspace=0.4)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Accuracy for different education levels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_accuracy_edu_method = accuracy_per_groupby(df_merged, group_by=[\"Education\", \"method\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_edu_method, \"XAI Method\", \"Accuracy\", \"Accuracy Scores for different XAI Methods for different Education Levels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_edu_method,\"education\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "aab16720",
   "metadata": {},
   "source": [
    "## Accuracy for different ML-Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf075171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_mlex_method = accuracy_per_groupby(df_merged, group_by=[\"ML Experience\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ff9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_mlex_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different ML Experience Length\", mean_idx_order=[\"Not at all\", \"Under 1 year\", \"Between 1 and 3 years\", \"Between 3 and 5 years\", \"More than 5 years\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_mlex_method,\"ml_exp\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "b62fd56b",
   "metadata": {},
   "source": [
    "## Accuracy for different perceived XAI-Experience Usefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d674cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_xaiusef_method = accuracy_per_groupby(df_merged, group_by=[\"ML Experience Usefulness\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_xaiusef_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different perceived ML-Experience Usefulness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_xaiusef_method,\"ml_exp_self\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "2266d0b8",
   "metadata": {},
   "source": [
    "## Accuracy for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_model_method = accuracy_per_groupby(df_merged, group_by=[\"model\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07abbe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_model_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Models\", drop_duplicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "line_plot(df_accuracy_model_method, \"XAI Method\", \"Accuracy\",\"models\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "5067abb4",
   "metadata": {},
   "source": [
    "## Accuracy for colorblindness yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88bdc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_colorb_method = accuracy_per_groupby(df_merged, group_by=[\"Color Blindness\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_colorb_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Color Blindness\", drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d43f60",
   "metadata": {},
   "source": [
    "## Accuracy for visual impairment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_visimp_method = accuracy_per_groupby(df_merged, group_by=[\"Visual Impairment Affect\", \"method\"], drop_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c3bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_visimp_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Visual Impairment Affect\", drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_visimp_method,\"visual\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "8f900b8a",
   "metadata": {},
   "source": [
    "# Hypotheses testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab782f",
   "metadata": {},
   "source": [
    "## One sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f955162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_result(pval, alpha, mean_h_0):\n",
    "    print(f\"p-value: {pval}\")\n",
    "    if pval < alpha:\n",
    "        print(f\"Reject H0: accuracy_mean <= {mean_h_0} \\n\")\n",
    "    else:\n",
    "        print(\"Accept H0 \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_t_test(accuracies, mean_h_0, alpha):\n",
    "    tset, pval = ttest_1samp(a=accuracies, popmean=mean_h_0, alternative=\"greater\")\n",
    "    print(f\"p-value: {pval}\")\n",
    "    if pval < alpha:\n",
    "        print(f\"Reject H0: accuracy_mean <= {mean_h_0} \\n\")\n",
    "    else:\n",
    "        print(\"Accept H0 \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fa0d05",
   "metadata": {},
   "source": [
    "### Testing overall mean - H0: mean <= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_h_0 = 0.5\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mean = df_accuracy_convergence[\"accuracy\"].mean()\n",
    "accuracy_per_case_method = df_accuracy_convergence[\"accuracy\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a70e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tset, pval = ttest_1samp(accuracy_per_case_method, mean_h_0, alternative=\"greater\")\n",
    "print_test_result(pval, alpha, mean_h_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144a5e1",
   "metadata": {},
   "source": [
    "### Testing individual method mean - H0: accuracy <= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc0994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e587571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_convergence_p = df_accuracy_convergence.reset_index().pivot(index=\"case\", columns=\"method\", values=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b407a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_convergence_p.apply(lambda accuracies_method: perform_t_test(accuracies_method, mean_h_0, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d1b70",
   "metadata": {},
   "source": [
    "## Paired t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32cd939",
   "metadata": {},
   "source": [
    "### Testing all pairwise H0: accuarcy_method_i <= accuarcy_method_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f07973",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3634c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}