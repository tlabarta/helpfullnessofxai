{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9ef7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data_handler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets\n",
    "import os\n",
    "from itertools import chain, product\n",
    "\n",
    "from scipy.stats import ttest_1samp, ttest_rel, t\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.path.curdir, \"data\", \"survey_results\", \"data_tu-helpfulness-of-xai_2022-07-13_13-03.xlsx\")\n",
    "DATA_PREPARED_PATH = f\"{os.path.splitext(DATA_PATH)[0]}_PREPARED{os.path.splitext(DATA_PATH)[1]}\"\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "df_merged = pd.read_excel(DATA_PREPARED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "META_DATA_PATH = os.path.join(os.path.curdir, \"data\", \"survey_results\", \"question_meta_data.xlsx\")\n",
    "df_quest_meta = pd.read_excel(META_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2286ea0",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Calculation & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de567e7",
   "metadata": {},
   "source": [
    "### Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_groupby(df_merged, group_by=[\"method\"], drop_na=False):\n",
    "    # accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    schema_cols = [df_merged[column].drop_duplicates() for column in group_by + [\"is_pred_correct\", \"response\"]]\n",
    "    schema_col_names = [ser.name for ser in schema_cols]\n",
    "    df_schema = pd.DataFrame(list(product(*schema_cols))).groupby(list(np.arange(len(schema_cols)))).count()\n",
    "    df_schema = df_schema.reset_index()\n",
    "    df_schema.columns=schema_col_names\n",
    "    \n",
    "    ser_denominators = df_merged.groupby(by=group_by, dropna=drop_na)[\"response\"].count().sort_index()\n",
    "    df_numerators = df_merged.groupby(by=group_by + [\"is_pred_correct\", \"response\"], dropna=drop_na)[\"response\"].count().to_frame(\"count\").reset_index()\n",
    "    df_numerators = df_schema.merge(right=df_numerators, on=schema_col_names, how=\"left\").fillna(0)\n",
    "    ser_numerators = df_numerators[df_numerators[\"is_pred_correct\"] == df_numerators[\"response\"]].groupby(group_by, dropna=drop_na)[\"count\"].sum().sort_index()\n",
    "    df_accuracies = (ser_numerators / ser_denominators).to_frame(\"accuracy\")\n",
    "    return df_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_per_groupby(df_merged, group_by=[\"method\"], drop_na=True):\n",
    "    # sensitivity = TP / (TP + FN)\n",
    "    schema_cols = [df_merged[column].drop_duplicates() for column in group_by + [\"is_pred_correct\", \"response\"]]\n",
    "    schema_col_names = [ser.name for ser in schema_cols]\n",
    "    df_schema = pd.DataFrame(list(product(*schema_cols))).groupby(list(np.arange(len(schema_cols)))).count()\n",
    "    df_schema = df_schema.reset_index()\n",
    "    df_schema.columns=schema_col_names\n",
    "    \n",
    "    df_merged_filt = df_merged[(df_merged[\"is_pred_correct\"] == True)]\n",
    "    ser_denominators = df_merged_filt.groupby(by=group_by, dropna=drop_na)[\"response\"].count().sort_index()\n",
    "    df_numerators = df_merged_filt.groupby(by=group_by + [\"is_pred_correct\", \"response\"], dropna=drop_na)[\"response\"].count().to_frame(\"count\").reset_index()\n",
    "    df_numerators = df_schema.merge(right=df_numerators, on=schema_col_names, how=\"left\").fillna(0)\n",
    "    ser_numerators = df_numerators[df_numerators[\"is_pred_correct\"] == df_numerators[\"response\"]].groupby(group_by, dropna=drop_na)[\"count\"].sum().sort_index()\n",
    "    df_sensitivity = (ser_numerators / ser_denominators).to_frame(\"sensitivity\")\n",
    "    return df_sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity_per_groupby(df_merged, group_by=[\"method\"], drop_na=True):\n",
    "    # specificity = TN / (TN + FP)\n",
    "    schema_cols = [df_merged[column].drop_duplicates() for column in group_by + [\"is_pred_correct\", \"response\"]]\n",
    "    schema_col_names = [ser.name for ser in schema_cols]\n",
    "    df_schema = pd.DataFrame(list(product(*schema_cols))).groupby(list(np.arange(len(schema_cols)))).count()\n",
    "    df_schema = df_schema.reset_index()\n",
    "    df_schema.columns=schema_col_names\n",
    "    \n",
    "    df_merged_filt = df_merged[(df_merged[\"is_pred_correct\"] == False)]\n",
    "    ser_denominators = df_merged_filt.groupby(by=group_by, dropna=drop_na)[\"response\"].count().sort_index()\n",
    "    df_numerators = df_merged_filt.groupby(by=group_by + [\"is_pred_correct\", \"response\"], dropna=drop_na)[\"response\"].count().to_frame(\"count\").reset_index()\n",
    "    df_numerators = df_schema.merge(right=df_numerators, on=schema_col_names, how=\"left\").fillna(0)\n",
    "    ser_numerators = df_numerators[df_numerators[\"is_pred_correct\"] == df_numerators[\"response\"]].groupby(group_by, dropna=drop_na)[\"count\"].sum().sort_index()\n",
    "    df_specificity = (ser_numerators / ser_denominators).to_frame(\"specificity\")\n",
    "    return df_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_convergence(df_metric):\n",
    "    metric_name = df_metric.columns[0]\n",
    "    return df_metric.groupby(level=0).expanding().mean().reset_index(level=[1, 2]).\\\n",
    "            pivot(index=\"case\", columns=\"method\", values=metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c421b0f6",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_value_frequencies(df_metric_freq, df_metric_means, metric=\"Accuracy\", size=(16, 4)):\n",
    "    ax = df_metric_freq[df_metric_means.index].transpose().plot.bar(figsize=size)\n",
    "    ax.set_ylabel(f\"Number Participants who reached {metric} score\")\n",
    "    ax.xaxis.set_tick_params(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62818efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_boxplot(df_metrics_pivot, xlabel=\"XAI-Method\", ylabel=\"Accuracy\", title=\"\", size=(16, 4)):\n",
    "    metric_mean_sorted = df_metrics_pivot.mean(axis=0).sort_values(ascending=False)\n",
    "    xai_mean_sorted = metric_mean_sorted.index.values\n",
    "    df_metrics_pivot = df_metrics_pivot[xai_mean_sorted]\n",
    "    ax, bp = df_metrics_pivot.boxplot(figsize=size, showmeans=True, meanline=True, medianprops={\"color\":\"red\"}, return_type=\"both\")\n",
    "    \n",
    "    m1 = df_metrics_pivot.mean()\n",
    "    for i, line in enumerate(bp['means']):\n",
    "        x, y = line.get_xydata()[0]\n",
    "        y = y * 1.01\n",
    "        text = f\"mean = {metric_mean_sorted[i].round(2)}\"\n",
    "        ax.annotate(text, xy=(x, y))\n",
    "        \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_yticks(pd.unique(df_metrics_pivot.to_numpy().flatten()))\n",
    "    ax.grid(axis=\"x\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1dddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_freq_and_boxplot(df_metric_freq, df_metric_means, df_metrics_pivot, metric=\"Accuracy\", size=(10, 7)):\n",
    "    xai_mean_sorted = df_metric_means.index.values\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=size)\n",
    "    df_metric_freq[xai_mean_sorted].transpose().plot.bar(ax=ax1)\n",
    "    ax1.set_ylabel(f\"Number Participants who reached \\n {metric} Score\")\n",
    "    ax1.xaxis.set_tick_params(rotation=0)\n",
    "    ax1.set_xlabel(\"\")\n",
    "    ax1.legend(edgecolor=\"black\")\n",
    "\n",
    "    df_metrics_pivot = df_metrics_pivot[xai_mean_sorted]\n",
    "    bp = df_metrics_pivot.boxplot(figsize=size, showmeans=True, meanline=True, medianprops={\"color\":\"red\"}, return_type=\"dict\", ax=ax2)\n",
    "    \n",
    "    m1 = df_metrics_pivot.mean()\n",
    "    for i, line in enumerate(bp['means']):\n",
    "        x, y = line.get_xydata()[0]\n",
    "        y = y * 1.01\n",
    "        mean = df_metric_means.values[i][0].round(2)\n",
    "        format_float=\"{:.2f}\".format(mean)\n",
    "        text = f\"mean = {format_float}\"\n",
    "        ax2.annotate(text, xy=(x, y))\n",
    "        \n",
    "    ax2.set_ylabel(metric)\n",
    "    ax2.set_yticks(pd.unique(df_metrics_pivot.to_numpy().flatten())) # np.arange(0, 1.1, 0.1)\n",
    "    ax2.grid(axis=\"x\")\n",
    "    fig.supxlabel(\"XAI Method\", y=0.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"freq_boxplot_{metric.lower()}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e65d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_sens_spec(df_acc_mean, df_sens_mean, df_spec_mean, title_addition=\"\", size=(10, 4)):\n",
    "    xai_acc_sorted = df_acc_mean.sort_values(by=\"mean\", ascending=False).index.values\n",
    "    df_acc_mean = df_acc_mean.reindex(xai_acc_sorted)\n",
    "    df_sens_mean = df_sens_mean.reindex(xai_acc_sorted)\n",
    "    df_spec_mean = df_spec_mean.reindex(xai_acc_sorted)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=size)\n",
    "    ax.scatter(x=df_acc_mean.index, y=df_acc_mean, c=\"black\", label=\"Accuracy\", marker=\"s\")\n",
    "    ax.scatter(x=df_sens_mean.index, y=df_sens_mean, c=\"darkorange\", label=\"Sensitivity\")\n",
    "    ax.scatter(x=df_spec_mean.index, y=df_spec_mean, c=\"olivedrab\", label=\"Specificity\", marker=\"^\")\n",
    "    ax.plot(df_sens_mean[\"mean\"].index, [0.5] * len(df_sens_mean), color=\"indianred\", linestyle='dashed', label=\"baseline\")\n",
    "    #ax.set_title(f\"{title_addition} Performance Ratios for chosen XAI-Methods ({len(df)-1} participants considered)\", size=15)\n",
    "    ax.set_xlabel(\"XAI-Method\", size=13)\n",
    "    ax.set_ylabel(\"Ratio\", size=13)\n",
    "    for i, txt in enumerate(df_acc_mean[\"mean\"].round(2)):\n",
    "        ax.annotate(txt, (list(df_acc_mean.index)[i], list(df_acc_mean[\"mean\"])[i]))\n",
    "    for i, txt in enumerate(df_sens_mean[\"mean\"].round(2)):\n",
    "        ax.annotate(txt, (list(df_sens_mean.index)[i], list(df_sens_mean[\"mean\"])[i]))\n",
    "    for i, txt in enumerate(df_spec_mean[\"mean\"].round(2)):\n",
    "        ax.annotate(txt, (list(df_spec_mean.index)[i], list(df_spec_mean[\"mean\"])[i]))\n",
    "    ax.legend(loc=\"best\", edgecolor=\"black\")\n",
    "    ax.tick_params(labelright=True)\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    ax.set_yticks([0, 0.25, 0.5, 0.75, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"metrics_overview.pdf\") # sens_vs_spec.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aac06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_convergence(df_metrics_conv, metric_name=\"Accuracy\"):\n",
    "    methods_sorted = df_metrics_conv.iloc[-1].sort_values(ascending=False).index.values\n",
    "    df_metrics_conv = df_metrics_conv[methods_sorted]\n",
    "    \n",
    "    methods_names = methods_sorted.copy()\n",
    "    methods_names.sort()\n",
    "    colors =[\"darkorange\", \"olivedrab\",\"lightseagreen\",\"darkslategrey\",\"royalblue\",\"mediumvioletred\"]\n",
    "    line = [\"dotted\",\"dashed\",\"dashdot\",\"dotted\",\"dashed\",\"dashdot\"]\n",
    "    colors_dict = dict(zip(methods_names, colors))\n",
    "    line_dict = dict(zip(methods_sorted, line))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.set_xlabel(\"Number Participants\", size=13)\n",
    "    ax.set_ylabel(metric_name, size=13)\n",
    "    #ax.set_title(f\"Convergence of {metric_name} as Number of Participants increase\", size=15)\n",
    "    df_metrics_conv.apply(lambda method_conv: ax.plot(list(range(len(method_conv))), method_conv, label=method_conv.name, color=colors_dict[method_conv.name],ls=line_dict[method_conv.name]))\n",
    "    ax.legend(loc=\"upper right\", edgecolor=\"black\")\n",
    "    ax.tick_params(labelright=True)\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    plt.savefig(\"convergence.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb30e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2_indexes_1_plot(df_double_index, xlabel, ylabel, title, drop_na=True, drop_duplicates=True, mean_idx_order=None):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "    plt.setp(ax, ylim=(0, 1.1))\n",
    "    if drop_duplicates:\n",
    "        ser_level_1_count = df_merged.drop_duplicates(\"case\").groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "    else:\n",
    "        ser_level_1_count = df_merged.groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "                                                                                                                            \n",
    "    ser_acc_mean = df_double_index.mean(level=0)[df_double_index.columns[0]]\n",
    "    # reorder bars in barplot as specified\n",
    "    if mean_idx_order:\n",
    "        ser_acc_mean = ser_acc_mean.reindex(mean_idx_order)\n",
    "                                                                                                                         \n",
    "    pps = ax[0].bar(ser_acc_mean.index, ser_acc_mean)\n",
    "    for p in pps:\n",
    "        height = p.get_height()\n",
    "        ax[0].text(x=p.get_x() + p.get_width() / 2, y=height+.05,\n",
    "          s=round(height, 2),\n",
    "          ha='center', size=12)\n",
    "    ax[0].set_xlabel(ser_acc_mean.index.name, size=15)\n",
    "    ax[0].set_ylabel(\"Accuracy\", size=15)\n",
    "    ax[0].set_title(f\"Mean Accuracy over all XAI-Methods per {ser_acc_mean.index.name}\", size=20)\n",
    "    \n",
    "    for idx_level_1 in df_double_index.index.levels[0]:\n",
    "        ax[1].plot(df_double_index.loc[idx_level_1].index, list(df_double_index.loc[idx_level_1][df_double_index.columns[0]]), label=f\"{idx_level_1} ({ser_level_1_count[idx_level_1]})\")\n",
    "        ax[1].scatter(df_double_index.loc[idx_level_1].index, list(df_double_index.loc[idx_level_1][df_double_index.columns[0]]))\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel(xlabel, size=15)\n",
    "    ax[1].set_ylabel(ylabel, size=15)\n",
    "    ax[1].set_title(title, size=20)\n",
    "    plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.3, wspace=0.4)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2405a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(df_double_index,filename ,drop_na=True, drop_duplicates=True, mean_idx_order=None):\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    if drop_duplicates:\n",
    "        ser_level_1_count = df_merged.drop_duplicates(\"case\").groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "    else:\n",
    "        ser_level_1_count = df_merged.groupby(df_double_index.index.levels[0].name, dropna=drop_na)[df_merged.columns[0]].count()\n",
    "\n",
    "    ser_acc_mean = df_double_index.mean(level=0)[df_double_index.columns[0]]\n",
    "    # reorder bars in barplot as specified\n",
    "    if mean_idx_order:\n",
    "        ser_acc_mean = ser_acc_mean.reindex(mean_idx_order)\n",
    "\n",
    "    pps = ax.bar(ser_acc_mean.index, ser_acc_mean,color=\"olivedrab\")\n",
    "    for p in pps:\n",
    "        height = p.get_height()\n",
    "        ax.text(x=p.get_x() + p.get_width() / 2, y=height+.05,\n",
    "          s=round(height, 2),\n",
    "          ha='center', size=12)\n",
    "    ax.set_xlabel(ser_acc_mean.index.name, size=15)\n",
    "    ax.set_ylabel(\"Accuracy\", size=15)\n",
    "    #ax.set_title(f\"Mean Accuracy over all XAI-Methods per {ser_acc_mean.index.name}\", size=20)\n",
    "    ax.tick_params(labelright=True)\n",
    "    ax.set_ylim([0, 1])\n",
    "    plt.savefig(filename+\".svg\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4314b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot(df_double_index, xlabel, ylabel,filename, drop_na=True):\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "    colors =[\"darkorange\",\"olivedrab\"]\n",
    "    line = [\"dashed\",\"dashdot\"]\n",
    "    idx_level_1 = df_double_index.index.levels[0]\n",
    "\n",
    "    for i in range(idx_level_1.shape[0]):\n",
    "        ax.plot(df_double_index.loc[idx_level_1[i]].index, list(df_double_index.loc[idx_level_1[i]][df_double_index.columns[0]]),\n",
    "                label=f\"{idx_level_1[i]}\",color=colors[i],ls=line[i]) #({ser_level_1_count[idx_level_1]})\n",
    "        ax.scatter(df_double_index.loc[idx_level_1[i]].index, list(df_double_index.loc[idx_level_1[i]][df_double_index.columns[0]]),\n",
    "                   color=colors[i])\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_xlabel(xlabel, size=13)\n",
    "    ax.set_ylabel(ylabel, size=13)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.tick_params(labelright=True)\n",
    "    plt.savefig(filename+\".svg\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e652a0",
   "metadata": {},
   "source": [
    "### Testing & effect size functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isn't used currently\n",
    "def print_test_result(pval, alpha, mean_h_0):\n",
    "    print(f\"p-value: {pval}\")\n",
    "    if pval < alpha:\n",
    "        print(f\"Reject H0: accuracy_mean <= {mean_h_0} \\n\")\n",
    "    else:\n",
    "        print(\"Can't reject H0 \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9513aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_t_test(accuracies, mean_h_0, alpha, alternative):\n",
    "    tset, pval = ttest_1samp(a=accuracies, popmean=mean_h_0, alternative=alternative)\n",
    "    print(accuracies.name)\n",
    "    print(f\"p-value: {pval.round(3)}\")\n",
    "    if pval < alpha:\n",
    "        print(f\"Reject H0: accuracy_mean <= {mean_h_0} \\n\")\n",
    "    else:\n",
    "        print(\"Can't reject H0 \\n\")\n",
    "    return tset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_t_test_with_flexible_alternative(metrics, mean_h_0, alpha):\n",
    "    h_a = None\n",
    "    sample_mean = metrics.mean()\n",
    "    if sample_mean < mean_h_0:\n",
    "        h_a = \"less\"\n",
    "    elif sample_mean > mean_h_0:\n",
    "        h_a = \"greater\"\n",
    "    else:\n",
    "        h_a = \"two-sided\"\n",
    "    tset, pval = ttest_1samp(a=metrics, popmean=mean_h_0, alternative=h_a)\n",
    "    \n",
    "    h_a_to_h_0_mapping = {\"less\": \">=\", \"greater\": \"<=\", \"two-sided\": \"equal\"}\n",
    "    print(f\"{metrics.name}:  sample_mean={sample_mean}\")\n",
    "    print(f\"H0: sample_mean {h_a_to_h_0_mapping[h_a]} {mean_h_0}\")\n",
    "    print(f\"p-value: {pval.round(3)}\")\n",
    "    if pval < alpha:\n",
    "        print(f\"Reject H0! (alpha={alpha})\\n\")\n",
    "    else:\n",
    "        print(f\"CAN'T reject H0: (alpha={alpha})\\n\")\n",
    "    return tset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb5c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_paired_test_results(df_metrics, df_metrics_mean, ALPHA):\n",
    "    paired_test_alternatives = []\n",
    "    paired_test_pvalues = []\n",
    "    df_metrics_mean = df_metrics_mean.sort_values(by=\"mean\", ascending=False)\n",
    "    xai_accuracy_sorted = df_metrics_mean.index.values\n",
    "    for method_i in xai_accuracy_sorted:\n",
    "        method_i_alternatives = []\n",
    "        method_i_pvalues = []\n",
    "        for method_j in xai_accuracy_sorted:\n",
    "            h_a = None\n",
    "            if df_metrics_mean.loc[method_i][\"mean\"] < df_metrics_mean.loc[method_j][\"mean\"]:\n",
    "                h_a = \"less\"\n",
    "            elif df_metrics_mean.loc[method_i][\"mean\"] > df_metrics_mean.loc[method_j][\"mean\"]:\n",
    "                h_a = \"greater\"\n",
    "            elif (df_metrics_mean.loc[method_i][\"mean\"] == df_metrics_mean.loc[method_j][\"mean\"]) & (method_i != method_j):\n",
    "                h_a = \"two-sided\"\n",
    "            method_i_alternatives.append(h_a)\n",
    "            if h_a is None:\n",
    "                method_i_pvalues.append(None)\n",
    "            else:\n",
    "                a = df_metrics[method_i].values\n",
    "                b = df_metrics[method_j].values\n",
    "                tset, pval = ttest_rel(a, b, alternative=h_a)\n",
    "                method_i_pvalues.append(pval)\n",
    "        paired_test_alternatives.append(method_i_alternatives)\n",
    "        paired_test_pvalues.append(method_i_pvalues)\n",
    "        \n",
    "    def alternative_formatter(x):\n",
    "        alt_str = None\n",
    "        if  x==\"less\":\n",
    "            alt_str = \"$<$\" \n",
    "        elif x==\"greater\":\n",
    "            alt_str = \"$>$\"\n",
    "        else:\n",
    "            alt_str = \"—\"\n",
    "        return alt_str\n",
    "        \n",
    "    def p_value_formatter(x):\n",
    "        pval_str = None\n",
    "        if x < 0.001:\n",
    "            pval_str = \"$<$ .001\"\n",
    "        elif np.isnan(x):\n",
    "            pval_str = \"—\"\n",
    "        else:\n",
    "            pval_str = f\".{str(round(x, 3)).split('.')[-1]}\"\n",
    "        return pval_str\n",
    "            \n",
    "    \n",
    "    df_paired_alternatives = pd.DataFrame(paired_test_alternatives, index=xai_accuracy_sorted, columns=xai_accuracy_sorted)\n",
    "    df_paired_alternatives = df_paired_alternatives.applymap(alternative_formatter)\n",
    "    df_paired_pvalues = pd.DataFrame(paired_test_pvalues, index=xai_accuracy_sorted ,columns=xai_accuracy_sorted)\n",
    "    df_paired_decision = df_paired_pvalues < ALPHA\n",
    "    df_paired_pvalues = df_paired_pvalues.applymap(p_value_formatter)\n",
    "    \n",
    "    return df_paired_alternatives, df_paired_pvalues, df_paired_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohen’s d for one-sample t-test\n",
    "def cohens_d(t_statistic, N):\n",
    "    return t_statistic / np.sqrt(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff25b45",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c27e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance level\n",
    "ALPHA = 0.05\n",
    "mean_h_0 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503bc7a0",
   "metadata": {},
   "source": [
    "## 1. Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = accuracy_per_groupby(df_merged, group_by=[\"method\", \"case\"])\n",
    "df_acc_pivot = df_acc.reset_index().pivot(index=\"case\", columns=\"method\", values=\"accuracy\")\n",
    "df_acc_frequencies = df_acc_pivot.apply(lambda x: x.value_counts())\n",
    "df_acc_conv = get_metric_convergence(df_acc)\n",
    "df_acc_mean = df_acc_pivot.mean().to_frame(\"mean\").sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7feb37",
   "metadata": {},
   "source": [
    "### Accuracy boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a559e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_metric_boxplot(df_acc_pivot, xlabel=\"XAI Method\", title=\"\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f921c1e",
   "metadata": {},
   "source": [
    "### Accuracy convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772cd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_convergence(df_acc_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef82c2b",
   "metadata": {},
   "source": [
    "### Accuracy values  frequencies (all possible discrete according to question resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_acc_freq = plot_metric_value_frequencies(df_acc_frequencies, df_acc_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_freq_and_boxplot(df_acc_frequencies, df_acc_mean, df_acc_pivot, metric=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59784d8",
   "metadata": {},
   "source": [
    "### Significance & Effect Size: Accuracy comparisons to random baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0defbf7d",
   "metadata": {},
   "source": [
    "#### 1-sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91963358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with flexibile alternative\n",
    "ser_acc_1_sample_t_values = df_acc_pivot.apply(lambda accuracies_method: perform_t_test_with_flexible_alternative(accuracies_method, mean_h_0, ALPHA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947fed9",
   "metadata": {},
   "source": [
    "#### Effect size (Cohens d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4427a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_acc = df_acc_pivot.shape[0]\n",
    "df_acc_1_sample_effect = ser_acc_1_sample_t_values.map(lambda t_val: cohens_d(t_val, N_acc)).to_frame(\"cohens_d\").sort_values(by=\"cohens_d\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef236204",
   "metadata": {},
   "source": [
    "### Significance: Accuracies pairwise between each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c27b6",
   "metadata": {},
   "source": [
    "#### Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66efa54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_paired_test_alternatives, df_acc_paired_test_pvalues, df_acc_paired_test_decision = get_pairwise_paired_test_results(df_acc_pivot, df_acc_mean, ALPHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_paired_test_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_paired_test_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce97af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_paired_test_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de71fd",
   "metadata": {},
   "source": [
    "## 2. Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd85468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens = sensitivity_per_groupby(df_merged, group_by=[\"method\", \"case\"])\n",
    "df_sens_pivot = df_sens.reset_index().pivot(index=\"case\", columns=\"method\", values=\"sensitivity\")\n",
    "df_sens_frequencies = df_sens_pivot.apply(lambda x: x.value_counts())\n",
    "df_sens_conv = get_metric_convergence(df_sens)\n",
    "df_sens_mean = df_sens_pivot.mean().to_frame(\"mean\").sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f19fb4",
   "metadata": {},
   "source": [
    "### Sensitivity boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b219dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\" # \"Sensitivity Variance among Participants per XAI-Method\"\n",
    "plot_metric_boxplot(df_sens_pivot, xlabel= \"XAI Method\", ylabel=\"Sensitiviy\", title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340384c",
   "metadata": {},
   "source": [
    "### Sensitvity convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed0bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_convergence(df_sens_conv, metric_name=\"Sensitivity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904f60e",
   "metadata": {},
   "source": [
    "### Sensitivity values  frequencies (all possible discrete according to question resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_value_frequencies(df_sens_frequencies, df_sens_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2991bd",
   "metadata": {},
   "source": [
    "### Significance & Effect Size: Sensitivity comparisons to random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_mean.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9975db4",
   "metadata": {},
   "source": [
    "#### 1-sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0389a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with flexibile alternative\n",
    "ser_sens_1_sample_t_values = df_sens_pivot.apply(lambda metric_method: perform_t_test_with_flexible_alternative(metric_method, mean_h_0, ALPHA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f946ac",
   "metadata": {},
   "source": [
    "#### Effect size (Cohens d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7fef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sens = df_sens_pivot.shape[0]\n",
    "df_sens_1_sample_effect = ser_sens_1_sample_t_values.map(lambda t_val: cohens_d(t_val, N_sens)).to_frame(\"cohens_d\").sort_values(by=\"cohens_d\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff5037c",
   "metadata": {},
   "source": [
    "### Significance: Sensitivity pairwise between in each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8cc3ed",
   "metadata": {},
   "source": [
    "#### Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd12f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_paired_test_alternatives, df_sens_paired_test_pvalues, df_sens_paired_test_decision = get_pairwise_paired_test_results(df_sens_pivot, df_sens_mean, ALPHA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1cdb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_paired_test_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_paired_test_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474dd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_paired_test_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d26968",
   "metadata": {},
   "source": [
    "## 3. Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6650b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec = specificity_per_groupby(df_merged, group_by=[\"method\", \"case\"])\n",
    "df_spec_pivot = df_spec.reset_index().pivot(index=\"case\", columns=\"method\", values=\"specificity\")\n",
    "df_spec_frequencies = df_spec_pivot.apply(lambda x: x.value_counts())\n",
    "df_spec_conv = get_metric_convergence(df_spec)\n",
    "df_spec_mean = df_spec_pivot.mean().to_frame(\"mean\").sort_values(by=\"mean\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37acd0",
   "metadata": {},
   "source": [
    "### Specificity boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe6d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_boxplot(df_spec_pivot, ylabel=\"Specificity\" ,title=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175a294",
   "metadata": {},
   "source": [
    "### Specificity convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021619f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_convergence(df_spec_conv, metric_name=\"Specificity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b54f5",
   "metadata": {},
   "source": [
    "### Specificity values frequencies (all possible discrete according to question resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_value_frequencies(df_spec_frequencies, df_spec_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41659bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_freq_and_boxplot(df_spec_frequencies, df_spec_mean, df_spec_pivot, metric=\"Specificity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b890759",
   "metadata": {},
   "source": [
    "### Significance & Effect Size: Specificity comparisons to random baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430622f",
   "metadata": {},
   "source": [
    "#### 1-sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with flexibile alternative\n",
    "ser_spec_1_sample_t_values = df_spec_pivot.apply(lambda metric_method: perform_t_test_with_flexible_alternative(metric_method, mean_h_0, ALPHA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c01249e",
   "metadata": {},
   "source": [
    "#### Effect size (Cohens d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe32eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_spec = df_spec_pivot.shape[0]\n",
    "df_spec_1_sample_effect = ser_spec_1_sample_t_values.map(lambda t_val: cohens_d(t_val, N_sens)).to_frame(\"cohens_d\").sort_values(by=\"cohens_d\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_1_sample_effect.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4022af",
   "metadata": {},
   "source": [
    "### Significance: Specificity pairwise between in each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ceae0d",
   "metadata": {},
   "source": [
    "#### Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f27a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_paired_test_alternatives, df_spec_paired_test_pvalues, df_spec_paired_decision = get_pairwise_paired_test_results(df_spec_pivot, df_spec_mean, ALPHA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03338bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_paired_test_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f348b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_paired_test_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828464e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec_paired_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c200e",
   "metadata": {},
   "source": [
    "## 4. Accuracy vs. Sensitivity vs. Specificity per method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_sens_spec(df_acc_mean, df_sens_mean, df_spec_mean, title_addition=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48698abf",
   "metadata": {},
   "source": [
    "#### Sensitvity/ Specificity only on fixed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_img_idxs = df_quest_meta[\"img_idx\"].value_counts()[df_quest_meta[\"img_idx\"].value_counts() == 12].index\n",
    "df_quest_meta_fixed = df_quest_meta[df_quest_meta[\"img_idx\"].isin(fixed_img_idxs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3a082",
   "metadata": {},
   "source": [
    "## 5. Analysis: Participants characteristics on accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8356d",
   "metadata": {},
   "source": [
    "### Accuracy for different education levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abdc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_edu_method = accuracy_per_groupby(df_merged, group_by=[\"Education\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_edu_method, \"XAI Method\", \"Accuracy\", \"Accuracy Scores for different XAI Methods for different Education Levels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_edu_method,\"education\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab16720",
   "metadata": {},
   "source": [
    "### Accuracy for different ML-Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf075171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_mlex_method = accuracy_per_groupby(df_merged, group_by=[\"ML Experience\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ff9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_mlex_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different ML Experience Length\", mean_idx_order=[\"Not at all\", \"Under 1 year\", \"Between 1 and 3 years\", \"Between 3 and 5 years\", \"More than 5 years\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_mlex_method,\"ml_exp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62fd56b",
   "metadata": {},
   "source": [
    "### Accuracy for different perceived ML-Experience Usefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d674cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_xaiusef_method = accuracy_per_groupby(df_merged, group_by=[\"ML Experience Usefulness\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867296c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_xaiusef_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different perceived ML-Experience Usefulness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_xaiusef_method,\"ml_exp_self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531da57",
   "metadata": {},
   "source": [
    "### Accuracy for visual impairment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b864312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_visimp_method = accuracy_per_groupby(df_merged, group_by=[\"Visual Impairment Affect\", \"method\"], drop_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54d649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_visimp_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Visual Impairment Affect\", drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c2d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df_accuracy_visimp_method,\"visual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173388bd",
   "metadata": {},
   "source": [
    "### Accuracy for colorblindness yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de88eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_colorb_method = accuracy_per_groupby(df_merged, group_by=[\"Color Blindness\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d0064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_colorb_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Color Blindness\", drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266d0b8",
   "metadata": {},
   "source": [
    "## 6. Accuracy for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_model_method = accuracy_per_groupby(df_merged, group_by=[\"model\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07abbe67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_model_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Models\", drop_duplicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff99c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot(df_accuracy_model_method, \"XAI Method\", \"Accuracy\",\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe35a31",
   "metadata": {},
   "source": [
    "## 7. Metrics per questionnaire form (detect outlier questionnaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed8cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy_qustnr_method = accuracy_per_groupby(df_merged, group_by=[\"QUESTNNR\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc581e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_indexes_1_plot(df_accuracy_qustnr_method, \"XAI Method\", \"Accuracy\", \"Comparing Accuracy Scores for different Questionnaire Forms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d73d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
