{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9ef7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from methods import data_handler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets\n",
    "import os\n",
    "from itertools import chain, product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d5f67",
   "metadata": {},
   "source": [
    "## Read questionnaire information from picking procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaires = data_handler.get_questionaires(\"data2/questionaires_shuffled.pickle\")\n",
    "labels = data_handler.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6640676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_img_idx(img_idx, testset_path, labels):    \n",
    "    img_folder = datasets.ImageFolder(root=testset_path)\n",
    "    img_path = img_folder.imgs[img_idx][0]\n",
    "    img_name = img_path.split(os.sep)[-1]\n",
    "    # extract correct class\n",
    "    class_idx_true_str = img_path.split(os.sep)[-2]\n",
    "    img_label_true = labels[class_idx_true_str][1]\n",
    "    return img_label_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrich questionnaire data with image label names\n",
    "questionnaires_2 = []\n",
    "for questionnaire in tqdm(questionnaires):\n",
    "    questionnaire_2 = []\n",
    "    for question in questionnaire:\n",
    "        label = get_label_from_img_idx(question[0], \"data2/imagenetv2-matched-frequency-format-val\", labels)\n",
    "        question_labled = (label, ) + question        \n",
    "        questionnaire_2.append(question_labled)\n",
    "    questionnaires_2.append(questionnaire_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be42d6",
   "metadata": {},
   "source": [
    "## Load question codes used in SoSci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_list = []\n",
    "for i in range(1, 12+1):\n",
    "    codes = pd.read_csv(f\"questionaires_shuffle_order/questionaire_{i}.txt\", sep=\";\", names=[0, 1])[1]\n",
    "    codes = codes.str.extract(\"(\\w\\d{3})\")\n",
    "    codes = list(codes[0])\n",
    "    codes_list.append(codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee37a8",
   "metadata": {},
   "source": [
    "## Create questions meta data df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5444db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quest_meta = pd.DataFrame(list(chain(*questionnaires_2)))\n",
    "df_quest_meta[5] = list(chain(*codes_list))\n",
    "df_quest_meta.columns = [\"label\", \"img_idx\", \"model\", \"method\", \"is_pred_correct\", \"question_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf8b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_quest_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ca4bb",
   "metadata": {},
   "source": [
    "## Load and transform questionnaire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tu-helpfulness-of-xai_2022-06-23_20-20.xlsx\n",
    "df = pd.read_excel(\"data2/data_tu-helpfulness-of-xai_2022-06-23_20-20.xlsx\")\n",
    "df_answer_codes = pd.read_csv(\"data2/values_tu-helpfulness-of-xai_2022-06-28_11-48.csv\", sep='\\t', encoding='utf-16').set_index([\"VAR\", \"RESPONSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ef7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_answer_codes_to_textual(s, df_answer_codes):\n",
    "    def map_(s_name, e, df_answer_codes):\n",
    "        try:\n",
    "            return df_answer_codes.loc[s_name, e][\"MEANING\"]\n",
    "        except:\n",
    "            \n",
    "            return e\n",
    "    try:\n",
    "        return s.apply(lambda e: map_(s.name, e, df_answer_codes))\n",
    "    except:\n",
    "        print(\"Error in mapping column\", s.name)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3221b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_q_data_from_wide_to_long(df):\n",
    "    column_names_demographic = list(df[df.columns[df.columns.get_loc(\"DE02\"):df.columns.get_loc(\"FB01_01\")+1]].loc[0])\n",
    "    #delete column descriptions\n",
    "    df = df.drop(0)    \n",
    "    df_long = pd.melt(df, id_vars=\"CASE\", value_vars=df.columns.values[6:294]).dropna()\n",
    "    df_long.columns = [\"case\", \"question_code\", \"response\"]\n",
    "    df_long = df_long.sort_values(\"case\", )\n",
    "    # map response 1(Yes)/2(No) values to True/False\n",
    "    df_long[\"response\"] = df_long[\"response\"].apply(lambda x: True if x==1 else False)\n",
    "    df_long = df_long.reset_index(drop=True)\n",
    "    \n",
    "    df_demo = df[df.columns[df.columns.get_loc(\"DE02\"):df.columns.get_loc(\"FB01_01\")+1]]\n",
    "    df_demo = df_demo.apply(lambda s: map_answer_codes_to_textual(s, df_answer_codes))\n",
    "    df_demo.columns = column_names_demographic\n",
    "    num_questions = 24\n",
    "    df_demo = df_demo.apply(lambda s: s.repeat(num_questions)).reset_index(drop=True) \n",
    "    df_long = pd.concat([df_long[\"case\"], df_demo, df_long[df_long.columns[1:]]], axis=1)\n",
    "    \n",
    "    return df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531db118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = convert_q_data_from_wide_to_long(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c078ef35",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_long.merge(right=df_quest_meta)\n",
    "df_merged = df_merged.sort_values(\"case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de567e7",
   "metadata": {},
   "source": [
    "## Metrics on all images (fixed + random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e01e8",
   "metadata": {},
   "source": [
    "### Overall ability to guess model is correct if actually correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51274ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_guessed_correct_if_correct = df_merged[(df_merged[\"is_pred_correct\"] == True) & (df_merged[\"response\"] == True)].shape[0]\n",
    "num_correct_overall = df_merged[df_merged[\"is_pred_correct\"] == True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcff734",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_guessed_correct_if_correct / num_correct_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc6ea8",
   "metadata": {},
   "source": [
    "### Overall ability to guess model is wrong if actually wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b41eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_guessed_wrong_if_wrong = df_merged[(df_merged[\"is_pred_correct\"] == False) & (df_merged[\"response\"] == False)].shape[0]\n",
    "num_wrong_overall = df_merged[df_merged[\"is_pred_correct\"] == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_guessed_wrong_if_wrong / num_wrong_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d109a",
   "metadata": {},
   "source": [
    "### Ability for each XAI-method to guess model is correct/wrong if actually correct/wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f03b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_ratios(df_merged):\n",
    "    df_ratios_per_method = df_merged.groupby(by=[\"method\", \"is_pred_correct\"])[\"response\"].value_counts(normalize=True).to_frame(\"ratio\").reset_index()\n",
    "    df_ratios_per_method = df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == df_ratios_per_method[\"response\"]].reset_index(drop=True)\n",
    "    # append overall averages\n",
    "    df_ratios_per_method.loc[len(df_ratios_per_method)] = [\"Overall\", False, False, df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == False][\"ratio\"].mean()]\n",
    "    df_ratios_per_method.loc[len(df_ratios_per_method)] = [\"Overall\", True, True, df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == True][\"ratio\"].mean()]\n",
    "    return df_ratios_per_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4be8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_ratios_all(df_merged):\n",
    "    test = pd.DataFrame(list(product(df_ratios_per_method_case[\"case\"].drop_duplicates(), df_ratios_per_method_case[\"method\"].drop_duplicates(), df_ratios_per_method_case[\"is_pred_correct\"].drop_duplicates(), df_ratios_per_method_case[\"response\"].drop_duplicates()))).groupby([0, 1, 2, 3]).count()\n",
    "    test = test.reset_index()\n",
    "    test.columns=['case', 'method', 'is_pred_correct', 'response']\n",
    "    \n",
    "    df_ratios_per_method = df_merged.groupby(by=[\"method\", \"is_pred_correct\"])[\"response\"].value_counts(normalize=True).to_frame(\"ratio\").reset_index()\n",
    "    df_ratios_per_method = df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == df_ratios_per_method[\"response\"]].reset_index(drop=True)\n",
    "    # append overall averages\n",
    "    df_ratios_per_method.loc[len(df_ratios_per_method)] = [\"Overall\", False, False, df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == False][\"ratio\"].mean()]\n",
    "    df_ratios_per_method.loc[len(df_ratios_per_method)] = [\"Overall\", True, True, df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == True][\"ratio\"].mean()]\n",
    "    return df_ratios_per_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_per_method = create_individual_ratios(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_per_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratios(df_ratios_per_method, title_addition=\"\"):        \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.scatter(x=df_ratios_per_method[\"method\"].drop_duplicates(), y=df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == True][\"ratio\"], c=\"orange\", label=\"Guessed Correct when Model Correct\")\n",
    "    ax.scatter(x=df_ratios_per_method[\"method\"].drop_duplicates(), y=df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == False][\"ratio\"], c=\"purple\", label=\"Guessed Wrong when Model Wrong\")\n",
    "    ax.plot(df_ratios_per_method[\"method\"], [0.5] * len(df_ratios_per_method), color=\"red\", linestyle='dashed', label=\"baseline\")\n",
    "    ax.set_title(f\"{title_addition} Performance Ratios for chosen XAI-Methods ({len(df)} participants considered)\", size=15)\n",
    "    ax.set_xlabel(\"XAI-Method\", size=13)\n",
    "    ax.set_ylabel(\"Ratio\", size=13)\n",
    "    for i, txt in enumerate(df_ratios_per_method[\"ratio\"].round(2)):\n",
    "        ax.annotate(txt, (list(df_ratios_per_method[\"method\"])[i], list(df_ratios_per_method[\"ratio\"])[i]))\n",
    "    ax.legend(loc=\"best\", edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ratios(df_ratios_per_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48698abf",
   "metadata": {},
   "source": [
    "## Metrics only on fixed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_img_idxs = df_quest_meta[\"img_idx\"].value_counts()[df_quest_meta[\"img_idx\"].value_counts() == 12].index\n",
    "df_quest_meta_fixed = df_quest_meta[df_quest_meta[\"img_idx\"].isin(fixed_img_idxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264af424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_fixed = df_long.merge(right=df_quest_meta_fixed)\n",
    "df_merged_fixed = df_merged_fixed.sort_values(\"case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_per_method_fixed = create_individual_ratios(df_merged_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ratios(df_ratios_per_method_fixed, \"Fixed Imgs:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be527c41",
   "metadata": {},
   "source": [
    "## Convergence of ratio values as more participant results are taken into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_ratios_per_participant(df_merged):\n",
    "    # df_schema needed to get all TP,TN,FP,FN i.e. where value_counts() would evaluate nothing because not existent (0)\n",
    "    df_schema = pd.DataFrame(list(product(df_merged[\"case\"].drop_duplicates(), df_merged[\"method\"].drop_duplicates(), df_merged[\"is_pred_correct\"].drop_duplicates(), df_merged[\"response\"].drop_duplicates()))).groupby([0, 1, 2, 3]).count()\n",
    "    df_schema = df_schema.reset_index()\n",
    "    df_schema.columns=['case', 'method', 'is_pred_correct', 'response']\n",
    "    df_ratios_per_method_and_part = df_merged.groupby(by=[\"case\", \"method\", \"is_pred_correct\"])[\"response\"].value_counts(normalize=True).to_frame(\"ratio\").reset_index()\n",
    "    df_ratios_per_method_and_part = df_schema.merge(right=df_ratios_per_method_and_part, on=[\"case\", \"method\", \"is_pred_correct\", \"response\"], how=\"left\")\n",
    "    df_ratios_per_method_and_part = df_ratios_per_method_and_part.fillna(0)\n",
    "    # only filter for TP and TP (just for now, might get modified)\n",
    "    df_ratios_per_method_and_part = df_ratios_per_method_and_part[df_ratios_per_method_and_part[\"is_pred_correct\"] == df_ratios_per_method_and_part[\"response\"]].reset_index(drop=True)\n",
    "    return df_ratios_per_method_and_part.groupby(by=[\"method\", \"is_pred_correct\"]).expanding().mean()#.reset_index(level=2, drop=True)\n",
    "    #return df_ratios_per_method_and_part\n",
    "    \n",
    "    # df_ratios_per_method = df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == df_ratios_per_method[\"response\"]].reset_index(drop=True)\n",
    "    # append overall averages\n",
    "    # df_ratios_per_method.loc[len(df_ratios_per_method)] = [\"Overall\", False, False, df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == False][\"ratio\"].mean()]\n",
    "    # df_ratios_per_method.loc[len(df_ratios_per_method)] = [\"Overall\", True, True, df_ratios_per_method[df_ratios_per_method[\"is_pred_correct\"] == True][\"ratio\"].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6bb52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_convergence = create_individual_ratios_per_participant(df_merged)\n",
    "df_ratios_convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratio_convergence(df_ratios_convergence):\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.set_xlabel(\"Number Participants\", size=13)\n",
    "    ax.set_ylabel(\"Ratio\", size=13)\n",
    "    ax.set_title(\"Convergence of Ratios as Ratios are calculated over increasing Numbers of Participants\", size=15)\n",
    "    for method in df_ratios_convergence.index.get_level_values(0).drop_duplicates():\n",
    "        for outcome in df_ratios_convergence.index.get_level_values(1).drop_duplicates():\n",
    "            ax.plot(list(range(len(df_ratios_convergence.loc[method, outcome]))), df_ratios_convergence.loc[method, outcome][\"ratio\"], label=f\"{method}, {outcome}\")\n",
    "            # print(df_ratios_convergence.loc[method, outcome][\"ratio\"].iloc[-1])\n",
    "    ax.legend(loc=\"lower center\", edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437293a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ratio_convergence(df_ratios_convergence, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17f4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
