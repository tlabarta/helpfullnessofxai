{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (17): ReLU(inplace=True)\n    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): ReLU(inplace=True)\n    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (26): ReLU(inplace=True)\n    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): ReLU(inplace=True)\n    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (33): ReLU(inplace=True)\n    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (35): ReLU(inplace=True)\n    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils import data\n",
    "from torchvision.models import vgg19\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets.utils import download_url\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='./data/', transform=transform)\n",
    "\n",
    "dataloader = data.DataLoader(dataset=dataset, shuffle=False, batch_size=1)\n",
    "\n",
    "vgg19(pretrained=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "\n",
    "        # pretrained VGG19 network\n",
    "        self.vgg = vgg19(pretrained=True)\n",
    "\n",
    "        # access its last convolutional layer\n",
    "        self.features_conv = self.vgg.features[:36]\n",
    "\n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = self.vgg.classifier\n",
    "\n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "\n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "\n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "\n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view((1, -1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "\n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json to ./imagenet_class_index.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101.3%\n"
     ]
    }
   ],
   "source": [
    "# Download class labels from imagenet dataset\n",
    "download_url(\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\", \".\", \"imagenet_class_index.json\")\n",
    "\n",
    "with open(\"imagenet_class_index.json\", \"r\") as h:\n",
    "    labels = json.load(h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([386])\n"
     ]
    }
   ],
   "source": [
    "# initialize the VGG model\n",
    "vgg = VGG()\n",
    "\n",
    "# set the evaluation mode\n",
    "vgg.eval()\n",
    "\n",
    "# get the image from the dataloader\n",
    "img, _ = next(iter(dataloader))\n",
    "\n",
    "# get the most likely prediction of the model\n",
    "pred = vgg(img).argmax(dim=1)\n",
    "print(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fcbb7c15de0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 288x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPn0lEQVR4nO3dXYyc1X3H8d9vZ3e9XhuwCcUFjAIliIoiUsi2IklF2phKLkGQi1wQlQqaSO5F25AoEgJxgXpXKWmUVKkSWUCCGkQqEdIgmqQ4JFEUpUFdMKJgU95fDDY24cVm/bIzO/9ezFgyW2bXmf/MmUXn+5FWOzM7Z/9nnpn97TPPPOccR4QA1Gts1B0AMFqEAFA5QgCoHCEAVI4QACpHCACVWxEhYHuz7f+1/bTtGwvXPtP2z2zvsP247etL1j+mHw3b223fN4La62zfbfsJ2zttf7hw/S90t/1jtu+yPTXkerfb3mv7sWNuO9n2NttPdb+vL1z/S93t/6jt79teN6z6i408BGw3JP2LpL+QdL6kT9s+v2AXWpK+GBHnS7pE0t8Wrn/U9ZJ2jqCuJH1N0o8j4vclfbBkP2yfIelzkmYi4gJJDUlXD7nstyVtXnTbjZIeiIhzJT3QvV6y/jZJF0TEhZKelHTTEOu/w8hDQNIfS3o6Ip6NiHlJ35V0VaniEbE7Ih7uXj6gzh/AGaXqS5LtjZI+IenWknW7tU+SdKmk2yQpIuYj4s3C3RiXtNr2uKRpSa8Ms1hE/ELS64tuvkrSHd3Ld0j6ZMn6EXF/RLS6V38taeOw6i+2EkLgDEkvHXN9lwr/ER5l+yxJF0l6sHDpr0q6QVK7cF1JOlvSPknf6r4dudX2mlLFI+JlSV+W9KKk3ZLeioj7S9U/xoaI2N29vEfShhH04ajPSPpRqWIrIQRWBNtrJX1P0ucjYn/BuldI2hsRD5Wquci4pIslfSMiLpI0p+HuCr9D9733VeqE0emS1ti+plT9dxOdc+lHcj697ZvVeYt6Z6maKyEEXpZ05jHXN3ZvK8b2hDoBcGdE3FOytqSPSrrS9vPqvBX6uO3vFKy/S9KuiDi693O3OqFQymWSnouIfRHRlHSPpI8UrH/Uq7ZPk6Tu972lO2D7OklXSPrLKDioZyWEwH9LOtf22bYn1TkodG+p4ratzvvhnRHxlVJ1j4qImyJiY0Scpc5j/2lEFPtPGBF7JL1k+7zuTZsk7ShVX523AZfYnu4+F5s0mgOk90q6tnv5Wkk/KFnc9mZ13hJeGREHS9ZWRIz8S9Ll6hwRfUbSzYVr/4k6u36PSnqk+3X5iLbDn0q6bwR1/1DSbHcb/Luk9YXr/4OkJyQ9JulfJa0acr271Dn+0FRnT+izkt6nzqcCT0n6iaSTC9d/Wp1jY0dfg98stf3d7RSASq2EtwMARogQACpHCACVIwSAyhECQOVWVAjY3kL9OuvX/NhHXX9FhYCkkT4R1B9p/Zof+0jrr7QQAFBY0ZOFJifWxNTkup4/b7bmNDHeewCb28lBdss81vmFg5psTC9xD+fqLzMmZX7hkCYbq5M1ltBepn77kCbHlqg/lnz8Y73/58y35jS5xHMvSZHd/O79C5rNOU1MLDN4Mvm34uZCz58tu+0ltacn+q59+OAbas7PvesGGO/7t/ZhanKdLrngb/puP7b/UKq+m63l77SEGG+k2mdfROkX4aEjufqrJlPN22tzEwbFZO7lGskQ80Lun1Bjzxup9nMf7H+E/fZf/nPPn/F2AKgcIQBULhUCo5wgFMBg9B0CK2CCUAADkNkTGOkEoQAGIxMCK2aCUAD9G/qBQdtbbM/anm225oZdDsBvKRMCxzVBaERsjYiZiJhZ6kQgAKORCYGRThAKYDD6PgUrIlq2/07Sf6qzdNTtEfH4wHoGoIjUeZgR8UNJPxxQXwCMAGcMApUjBIDKFR1F6IUFNX5zoP9fMN/MdSA7CnBiVaq533o71b71yp5Ue7V7D2U9Ho0TT0y1HzuyNtU+1i41zHt57enc8zd2eD7VXsmh8NMv9L9E5tiR3s89ewJA5QgBoHKEAFA5QgCoHCEAVI4QACpHCACVIwSAyhECQOUIAaByhABQOUIAqBwhAFSOEAAqRwgAlSs6n4Bsxer+x3THdG5V28zSzpLUWptblXfqzcRcClJ6PoCshf39j2eXpGduyS1QtfnS7an2bzZzy77/6slzUu3PuTU323Z7sv/5MNov9G7LngBQOUIAqBwhAFSOEAAql1ma/EzbP7O9w/bjtq8fZMcAlJH5dKAl6YsR8bDtEyQ9ZHtbROwYUN8AFND3nkBE7I6Ih7uXD0jaKZYmB95zBnJMwPZZki6S9OAgfh+ActIhYHutpO9J+nxE/L+zSWxvsT1re3Z+4WC2HIABS4WA7Ql1AuDOiLjn3e4TEVsjYiYiZiYbuRVkAAxe5tMBS7pN0s6I+MrgugSgpMyewEcl/ZWkj9t+pPt1+YD6BaCQvj8ijIhfSvIA+wJgBDhjEKgcIQBUruh8AtEY08IJ/c8n4FZuffcYz2VeY4k13o/LRNnpGwattelDqfYX/tEzqfZfPyN3Gsrb7cOp9v+05uJU+//4wMdS7Ve/lnj9LfHSZ08AqBwhAFSOEAAqRwgAlSMEgMoRAkDlCAGgcoQAUDlCAKgcIQBUjhAAKkcIAJUjBIDKEQJA5QgBoHLFB7iH+5+RrHGomartHc+m2qudm8+gdTg3nn3U5k6bSLX/s3Uvpdo3Izefw08OnZJq/8Ce81Ltx1qRat+YT7z+lijNngBQOUIAqBwhAFSOEAAqN4i1CBu2t9u+bxAdAlDWIPYErldnWXIA70HZBUk3SvqEpFsH0x0ApWX3BL4q6QZJuQ/QAYxMZlXiKyTtjYiHlrnfFtuztmebzbl+ywEYkuyqxFfafl7Sd9VZnfg7i+8UEVsjYiYiZiYm1iTKARiGvkMgIm6KiI0RcZakqyX9NCKuGVjPABTBeQJA5QYygCgifi7p54P4XQDKYk8AqBwhAFSu7HwCljTW/3wCOjKfKt8+eDDV3h/6g1T712ZOTLVvrklsO0lr9uRO5zi4Ifc/49+euTjV/le/+b1U+z0HTki1f2PXSan2p+Wmw9DE/v5f/17oPaEAewJA5QgBoHKEAFA5QgCoHCEAVI4QACpHCACVIwSAyhECQOUIAaByhABQOUIAqBwhAFSOEAAqRwgAlSs6n4BbbY2/kRjT/+b+wXWmD4dPnU61P3habj6AI+tz8wGMNXOZf+LzC6n2fi43nv/w/tWp9u9r5rbfuonc45/YfyjVfvy1A323dat339kTACpHCACVIwSAyhECQOWyqxKvs3237Sds77T94UF1DEAZ2U8HvibpxxHxKduTknKHzwEU13cI2D5J0qWSrpOkiJiXlJsTHEBxmbcDZ0vaJ+lbtrfbvtU2yw4D7zGZEBiXdLGkb0TERZLmJN24+E62t9ietT07v5Bb/APA4GVCYJekXRHxYPf63eqEwjtExNaImImImckGhwyAlabvEIiIPZJesn1e96ZNknYMpFcAisl+OvD3ku7sfjLwrKS/zncJQEmpEIiIRyTNDKYrAEaBMwaByhECQOWKzieQ1mikmntiMtV+8q3cuVCrXp9ItW9P5OYjaMz3XqP+eEy93ky1X/X03lT79r7XUu09tSrVfsLJ/5mRm88g2onnr9Xq+SP2BIDKEQJA5QgBoHKEAFA5QgCoHCEAVI4QACpHCACVIwSAyhECQOUIAaByhABQOUIAqBwhAFSOEAAqV3Y+AVsx3n/u+KTc+vaN8dzD9VxuPoFTHs3NhzA233uN+eMx/tbhVPt48ZVc+6mpVHuf8/5Ue7Vy28/N3mPyS4ixxHwSh3u/9tkTACpHCACVIwSAyhECQOVSIWD7C7Yft/2Y7bts5478ACiu7xCwfYakz0maiYgLJDUkXT2ojgEoI/t2YFzSatvjkqYl5T5DAlBcZkHSlyV9WdKLknZLeisi7h9UxwCUkXk7sF7SVZLOlnS6pDW2r3mX+22xPWt7dr41139PAQxF5u3AZZKei4h9EdGUdI+kjyy+U0RsjYiZiJiZHF+TKAdgGDIh8KKkS2xP27akTZJ2DqZbAErJHBN4UNLdkh6W9D/d37V1QP0CUEhqRE1E3CLplgH1BcAIcMYgUDlCAKhc2fkEJGkskTuNXGbFdHI8eyu3vvyqJ15OtW+9ujfVfiES69tL8qpVufanb0i1b61bnWqf5YXc8+9mbj6DjFjib4c9AaByhABQOUIAqBwhAFSOEAAqRwgAlSMEgMoRAkDlCAGgcoQAUDlCAKgcIQBUjhAAKkcIAJUjBIDKlZ1PICI3pjq5PrzbufH0OnQk196J9eUljW84NVd/YiLZPvlyOZzbfuNP78/Vzz7/Y7nnz5OTufrt/uczWOrvjj0BoHKEAFA5QgCoHCEAVG7ZELB9u+29th875raTbW+z/VT3+/rhdhPAsBzPnsC3JW1edNuNkh6IiHMlPdC9DuA9aNkQiIhfSHp90c1XSbqje/kOSZ8cbLcAlNLvMYENEbG7e3mPpNyE8gBGJn1gMCJCUs+zMGxvsT1re3Z+4WC2HIAB6zcEXrV9miR1v/dcGicitkbETETMTDam+ywHYFj6DYF7JV3bvXytpB8MpjsASjuejwjvkvRfks6zvcv2ZyX9o6Q/t/2UpMu61wG8By07IiQiPt3jR5sG3BcAI8AZg0DlCAGgcmXnE2i35bcTHxPON1PlIzEeW1J+PHpWdjx7M7n9kvMBqDmfq7+QfP6S3Mj9z8y+epyaj6J3dfYEgMoRAkDlCAGgcoQAUDlCAKgcIQBUjhAAKkcIAJUjBIDKEQJA5QgBoHKEAFA5QgCoHCEAVI4QACpXdj4BW2o0+m8/nhuR7RjxfAALvdeIPy7J/kf28WfnM5iayrVPjadXevulrZrMtU/Np9B727EnAFSOEAAqRwgAlet3afIv2X7C9qO2v2973VB7CWBo+l2afJukCyLiQklPSrppwP0CUEhfS5NHxP0R0epe/bWkjUPoG4ACBnFM4DOSfjSA3wNgBFLnCdi+WVJL0p1L3GeLpC2SNDV+QqYcgCHoOwRsXyfpCkmbYomzUCJiq6StknTS1O+O+GwNAIv1FQK2N0u6QdLHIiKxpBCAUet3afKvSzpB0jbbj9j+5pD7CWBI+l2a/LYh9AXACHDGIFA5QgCoHCEAVK7ofAIx3lDr1BP7bt84cCTZgeQnlMnx7JEdDz9ibmfGsw9gPoP2iD9hTs6noLER/s/d17s2ewJA5QgBoHKEAFA5QgCoHCEAVI4QACpHCACVIwSAyhECQOUIAaByhABQOUIAqBwhAFSOEAAqRwgAlXN6jPdvU8zeJ+mFJe5yiqTXCnWH+iurfs2PvUT990fE77zbD4qGwHJsz0bEDPXrq1/zYx91fd4OAJUjBIDKrbQQ2Er9auvX/NhHWn9FHRMAUN5K2xMAUBghAFSOEAAqRwgAlSMEgMr9H6oviGtwwpVWAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the gradient of the output with respect to the parameters of the model\n",
    "pred[:, 386].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = vgg.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = vgg.get_activations(img).detach()\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'resize'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m\n\u001B[1;32m      2\u001B[0m img \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data/Elephant/elephant.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m----> 3\u001B[0m heatmap \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheatmap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m heatmap \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39muint8(\u001B[38;5;241m255\u001B[39m \u001B[38;5;241m*\u001B[39m heatmap)\n\u001B[1;32m      5\u001B[0m heatmap \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mapplyColorMap(heatmap, cv2\u001B[38;5;241m.\u001B[39mCOLORMAP_JET)\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'resize'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = np.asarray(cv2.imread('./data/Elephant/elephant.jpg'))\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('./map.jpg', superimposed_img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}