{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46eb10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/julianvonklitzing/opt/anaconda3/envs/xai_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:12: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_model import train, load_image, predict\n",
    "import Contrastive_Explanation_Method_master.Utils as utils\n",
    "from Contrastive_Explanation_Method_master.aen_CEM import AEADEN\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from dataset_handler import DatasetHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46776ae4",
   "metadata": {},
   "source": [
    "# 1. Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34106e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/julianvonklitzing/opt/anaconda3/envs/xai_env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.VGG16(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a63e6",
   "metadata": {},
   "source": [
    "# 2. Predict with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01982763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "Predicted: [('n02111889', 'Samoyed', 0.10401), ('n02328150', 'Angora', 0.05517927), ('n02120079', 'Arctic_fox', 0.03914926)]\n"
     ]
    }
   ],
   "source": [
    "# auff채llig: Prediction ist deutlich unsicher als 체ber PyTorch oder 체ber Tensorflow 2.0 Model\n",
    "# Wurden hier vielleicht einfach noch nicht die Wahrscheinlichkeiten normalisiert?\n",
    "img = load_image(\"dog.jpg\")\n",
    "preds = predict(model, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17f8a2",
   "metadata": {},
   "source": [
    "# 3. CEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b7fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Probleme:\n",
    "\n",
    "# VGG laden -> tf 2  --> vielleicht musste nur zus채tzlich zu tf auch keras in version 1.15 installiert werden, damit klappt\n",
    "# CEM Implementierung -> tf 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3337e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class for the use in __init__ of AEDM() inspiried by class MNISTModel\n",
    "class Model():\n",
    "    def __init__(self, model, image_size, num_channels, num_labels):\n",
    "        self.model = model\n",
    "        self.image_size = image_size\n",
    "        self.num_channels = num_channels\n",
    "        self.num_labels = num_labels\n",
    "    def predict(self, data):\n",
    "        return self.model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5511e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data class for the use of utils.generate_data\n",
    "class Data():\n",
    "    def __init__(self, test_data, test_labels):\n",
    "        self.test_data = test_data\n",
    "        self.test_labels = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29297901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data\n",
    "test_data = np.expand_dims(img, axis=0).shape\n",
    "target_label = preds.argmax()\n",
    "test_labels = np.expand_dims(np.eye(1000)[target_label], axis=0)\n",
    "image_id = 0 \n",
    "\n",
    "\n",
    "data = Data(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01372242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paramters (was ist arg_b??)\n",
    "arg_max_iter = 10000\n",
    "arg_b = 0.1\n",
    "arg_init_const = 0.1\n",
    "arg_mode = \"PP\"\n",
    "arg_kappa = 10\n",
    "arg_beta = 0.1\n",
    "arg_gamma = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d278314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:0, infer label:258\n",
      "WARNING:tensorflow:From /Users/julianvonklitzing/Documents/GitHub/development/Contrastive_Explanation_Method_master/aen_CEM.py:89: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When using data tensors as input to a model, you should specify the `steps` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fd256cdfaf4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     attack = AEADEN(sess, model, mode = arg_mode, AE = None, batch_size=1, kappa=arg_kappa, init_learning_rate=1e-2,\n\u001b[0;32m---> 28\u001b[0;31m         binary_search_steps=arg_b, max_iterations=arg_max_iter, initial_const=arg_init_const, beta=arg_beta, gamma=arg_gamma)\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0madv_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/development/Contrastive_Explanation_Method_master/aen_CEM.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess, model, mode, AE, batch_size, kappa, init_learning_rate, binary_search_steps, max_iterations, initial_const, beta, gamma)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;31m# !!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImgToEnforceLabel_Score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImgToEnforceLabel_Score_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta_img_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"PN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/xai_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/xai_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 716\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    717\u001b[0m     return predict_loop(\n\u001b[1;32m    718\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/xai_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2414\u001b[0;31m       \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_steps_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/xai_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_steps_argument\u001b[0;34m(input_data, steps, steps_name)\u001b[0m\n\u001b[1;32m   1197\u001b[0m       raise ValueError('When using {input_type} as input to a model, you should'\n\u001b[1;32m   1198\u001b[0m                        ' specify the `{steps_name}` argument.'.format(\n\u001b[0;32m-> 1199\u001b[0;31m                            input_type=input_type_str, steps_name=steps_name))\n\u001b[0m\u001b[1;32m   1200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: When using data tensors as input to a model, you should specify the `steps` argument."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # load model after creating Session\n",
    "    model_vgg = tf.keras.applications.VGG16(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000\n",
    "    )\n",
    "    \n",
    "    model = Model(model=model_vgg, image_size=244, num_channels=3, num_labels=1000)\n",
    "\n",
    "    random.seed(121)\n",
    "    np.random.seed(1211)\n",
    "    orig_prob, orig_class, orig_prob_str = utils.model_prediction(model, np.expand_dims(img, axis=0))\n",
    "    target_label = orig_class\n",
    "    print(\"Image:{}, infer label:{}\".format(image_id, target_label))\n",
    "    \n",
    "    \n",
    "    orig_img, target = utils.generate_data(data, image_id, target_label)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    attack = AEADEN(sess, model, mode = arg_mode, AE = None, batch_size=1, kappa=arg_kappa, init_learning_rate=1e-2,\n",
    "        binary_search_steps=arg_b, max_iterations=arg_max_iter, initial_const=arg_init_const, beta=arg_beta, gamma=arg_gamma)\n",
    "\n",
    "    adv_img = attack.attack(orig_img, target)\n",
    "\n",
    "    adv_prob, adv_class, adv_prob_str = util.model_prediction(model, adv_img)\n",
    "    delta_prob, delta_class, delta_prob_str = util.model_prediction(model, orig_img-adv_img)\n",
    "\n",
    "    INFO = \"[INFO]id:{}, kappa:{}, Orig class:{}, Adv class:{}, Delta class: {}, Orig prob:{}, Adv prob:{}, Delta prob:{}\".format(image_id, arg_kappa, orig_class, adv_class, delta_class, orig_prob_str, adv_prob_str, delta_prob_str)\n",
    "    print(INFO)\n",
    "\n",
    "    suffix = \"id{}_kappa{}_Orig{}_Adv{}_Delta{}\".format(image_id, arg_kappa, orig_class, adv_class, delta_class)\n",
    "    arg_save_dir = \"{}_ID{}_Gamma_{}\".format(arg_mode, image_id, arg_gamma)\n",
    "    os.system(\"mkdir -p Results/{}\".format(arg_save_dir))\n",
    "    util.save_img(orig_img, \"Results/{}/Orig_original{}.png\".format(arg_save_dir, orig_class))\n",
    "    util.save_img(adv_img, \"Results/{}/Adv_{}.png\".format(arg_save_dir, suffix))\n",
    "    util.save_img(np.absolute(orig_img-adv_img)-0.5, \"Results/{}/Delta_{}.png\".format(arg_save_dir, suffix))\n",
    "\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000507d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
